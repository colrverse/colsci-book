[{"path":"index.html","id":"package-overview","chapter":"1 Package Overview","heading":"1 Package Overview","text":"pavo R package developed goal establishing flexible integrated workflow working spectral spatial colour data. includes functions take advantage new data classes work seamlessly importing raw spectra images, visualisation analysis. provides flexible ways input spectral data variety equipment manufacturers, process data, extract variables, produce publication-quality figures.pavo written following workflow mind:Organise data importing processing spectral image data (e.g., remove noise, negative values, smooth curves, etc.).Analyse resulting files, using spectral analyses shape (hue, saturation, brightness), visual models based perceptual data, /spatial adjacency boundary strength analyses.Visualise output, multiple options provided exploration analysis.\nFigure 1.1: non-exhaustive overview colour-pattern analysis workflow pavo, version 2.0, displaying key functions stage.\nremaining chapters begin detailing importing, processing visualisation spectral image data, moving discussion many analyses pavo allows. hope demonstrate flexibility pavo, provide cohesive, reproducible workflow colour pattern analysis within R. always, development version pavo can found github, stable release available via CRAN.","code":""},{"path":"index.html","id":"classes-and-attributes","chapter":"1 Package Overview","heading":"1.1 Classes and Attributes","text":"enable comprehensive workflow pavo, ’ve implemented expanded class system. Spectra class rspec long use one pavo’s spectral import processing functions, explicitly convert object using .rspec(). Similarly, images class rimg imported via getimg(), converted using .rimg(). results vismodel() objects class vismodel results colspace() , unsurprisingly, objects class colspace. classes inherit data.frame, contain suite attributes describe object’s characteristics (e.g. options used visual modelling selected visual system illuminant, properties modelled colourspace). easily viewed using summary function (rspec, rimg, vismodel, colspace object), return attributes summary data (appropriate) readable format.","code":""},{"path":"index.html","id":"suggestions-and-assistance","chapter":"1 Package Overview","heading":"1.2 Suggestions and Assistance","text":"suggestions, assistance /bug reports, suggest getting touch via colRverse discussion board. requires github account, however, don’t /want one feel free just email Tom ’ll get back soon possible. bug report, ’d appreciate also include reproducible example possible. Users familiar GitHub may prefer open issue project’s github page, make pull-request directly.","code":""},{"path":"index.html","id":"citation-of-methods-implemented-in-pavo","chapter":"1 Package Overview","heading":"1.3 Citation of methods implemented in pavo","text":"methods implemented pavo thoroughly described original publications, users refer details interpretation. reflectance shape variables (“objective colourimetrics”) particular relation signal production perception, see Andersson Prager (2006) Montgomerie (2006). Visual models based photon catches receptor noise detailed Vorobyev et al. (1998) Vorobyev et al. (1998), photoreceptor sensitivity curve estimation Govardovskii et al. (2000) Hart Vorobyev (2005). tetrahedral colourspace model implementations variable calculations, see Endler Mielke (2005) Stoddard Prum (2008), colour volume overlap see Stoddard Prum (2008) Stoddard Stevens (2011). Adjacency boundary strength analyses described Endler (2012) Endler, Cole, Kranz (2018), overall pattern contrast detailed Endler Mielke (2005). Users functions apply methods must cite original sources appropriate, along pavo :","code":"\ncitation(package = \"pavo\")To cite the package pavo in publications please use:\n\n  Maia R, Gruson H, Endler JA, White TE (2019). \"pavo 2: new\n  tools for the spectral and spatial analysis of colour in\n  R.\" _Methods in Ecology and Evolution_, *10*(7).\n  doi:10.1111/2041-210X.13174\n  <https://doi.org/10.1111/2041-210X.13174>.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {pavo 2: new tools for the spectral and spatial analysis of colour in R},\n    author = {Rafael Maia and Hugo Gruson and John A. Endler and Thomas E. White},\n    journal = {Methods in Ecology and Evolution},\n    year = {2019},\n    volume = {10},\n    number = {7},\n    page = {1097-1107},\n    doi = {10.1111/2041-210X.13174},\n  }"},{"path":"index.html","id":"acknowledgements","chapter":"1 Package Overview","heading":"1.4 Acknowledgements","text":"like thank Matthew D. Shawkey Stephanie M. Doucet insights support, Jarrod D. Hadfield Mary Caswell Stoddard sharing code helped us develop pavo’s capabilities.","code":""},{"path":"importing-processing-and-visualising-data.html","id":"importing-processing-and-visualising-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2 Importing, Processing, and Visualising Data","text":"","code":""},{"path":"importing-processing-and-visualising-data.html","id":"organizing-spectral-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.1 Organizing Spectral Data","text":"Let’s begin loading package.","code":"\n# Load the package, and set a global\n# random-number seed for the reproducible\n# generation of fake data later on.\nlibrary(pavo)\nset.seed(1612217)"},{"path":"importing-processing-and-visualising-data.html","id":"spectral-dataset-description","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.1.1 Spectral Dataset Description","text":"raw spectral data used example available package repository github, located . can download extract follow vignette exactly. Alternatively, data included RData file part package installation, can loaded directly (see ).data consist reflectance spectra, obtained using Avantes equipment software, seven bird species: Northern Cardinal Cardinalis cardinalis, Wattled Jacana Jacana jacana, Baltimore Oriole Icterus galbula, Peach-fronted Parakeet Aratinga aurea, American Robin Turdus migratorius, Sayaca Tanager Thraupis sayaca. Several individuals measured (sample size varies species), 3 spectra collected individual. However, number individuals measured per species uneven data additional peculiarities emphasize flexibility pavo offers, ’ll see .addition, pavo includes three datasets can called data() function. data(teal), data(sicalis), data(flowers) used vignette. See help files dataset information; via ?teal, ?sicalis, ?flowers.","code":""},{"path":"importing-processing-and-visualising-data.html","id":"importing-spectra","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.1.2 Importing spectra","text":"first thing need import spectral data R using function getspec(). ’s worth noting getspec() simply wrapper lr_get_spec() package lightr, specialised feature-rich package import spectral data metadata (Gruson, White, Maia 2019). Since example spectra obtained using Avantes software, need specify files .ttt extension. , data organized subdirectories species. getspec() search subdirectories recursively, may include names subdirectories spectra name desired. getspec() also uses parallel processing thanks future package. can check documentation (?future::plan()) details easy way set parallel processing cases use plan(\"multiprocess\") command. final issue data collected using computer international numbering input, means uses commas instead periods decimal separator. can specify function call., example, raw spectral files downloaded placed directory called /pavo/data_external/vignette, might execute following command see output:convenience, however, ’ve included spectra RData file package installation, simply load directly.can inspect resulting object:pavo imports spectra, creates object class rspec, inherits attributes data.frame class:already multiple spectra single data frame ’d like use pavo functions, can use command .rspec() convert rspec object. function attempt identify wavelength variable can specify column containing wavelengths whichwl argument. default way .rspec() handles reflectance data interpolate data 1-nm bins, commonly done spectral analyses. However, can turned using: interp = FALSE. example, create fake reflectance data (n.b. use simulate_spec(), results already rspec object), name column containing wavelengths (0.5-nm bins) wavelength rather wl (required pavo functions work) also put column containing wavelengths third rather first.can seen, .rspec() renames column containing wavelengths, sets first column, interpolates data 1-nm bins converts data rspec object. Note output returned specifying whichwl = 3:Finally, lim argument allows specify range wavelengths contained input dataset. useful either case dataset doesn’t contain information (hence specify column whichwl automatically find column .rspec()). Additionally, may useful focus subset wavelengths. example, wavelengths ranged 300 700 nm, however also specify restricted range wavelengths lim:want stress important check actual wavelengths contained data setting argument (.rspec() warn wavelengths data present range specified lim), otherwise .rspec() assume wavelengths exist fact may . example, set lim = c(300, 1000) plot results, reflectance values 700 1000 nm set equal since information wavelengths original dataset:","code":"\nspecs <- getspec(\"~/pavo/data_external/vignette\",\n  ext = \"ttt\",\n  decimal = \",\",\n  subdir = TRUE,\n  subdir.names = FALSE\n)\n# 213  files found; importing spectra\n# |================================================================================| 100%, ETA 00:00\nspecs <- readRDS(system.file(\"extdata/specsdata.rds\",\n  package = \"pavo\"\n))\n# The data set has 213 spectra,\n# from 300 to 700 nm, plus a 'wl' column\nspecs[1:10, 1:4]#>     wl cardinal.0001 cardinal.0002 cardinal.0003\n#> 1  300        5.7453        8.0612        8.0723\n#> 2  301        6.0181        8.3926        8.8669\n#> 3  302        5.9820        8.8280        9.0680\n#> 4  303        6.2916        8.7621        8.7877\n#> 5  304        6.6277        8.6819        9.3450\n#> 6  305        6.3347        9.6016        9.4834\n#> 7  306        6.3189        9.5712        9.3533\n#> 8  307        6.7951        9.4650        9.9492\n#> 9  308        7.0758        9.4677        9.8587\n#> 10 309        7.2126       10.6172       10.5396\ndim(specs)#> [1] 401 214\nis.rspec(specs)#> [1] TRUE\n# Create some fake reflectance data with\n# wavelength column arbitrarily titled\n# and not first in the data frame:\nfakedat <- data.frame(\n  refl1 = rnorm(n = 801),\n  refl2 = rnorm(n = 801),\n  wavelength = seq(300, 700, by = .5)\n)\nhead(fakedat)#>          refl1      refl2 wavelength\n#> 1 -0.032893386  0.5059612      300.0\n#> 2 -0.478552738 -1.1526035      300.5\n#> 3 -0.190687886 -1.0708952      301.0\n#> 4 -0.008977959 -1.9871907      301.5\n#> 5 -0.443133039 -0.3910143      302.0\n#> 6  0.032110206 -0.5403221      302.5\nis.rspec(fakedat)#> [1] FALSE\nfakedat.new <- as.rspec(fakedat)#> wavelengths found in column 3#> The spectral data contain 443 negative value(s),\n#>  which may produce unexpected results if used in models.\n#> Consider using procspec() to correct them.\nis.rspec(fakedat.new)#> [1] TRUE\nhead(fakedat.new)#>    wl       refl1       refl2\n#> 1 300 -0.03289339  0.50596119\n#> 2 301 -0.19068789 -1.07089518\n#> 3 302 -0.44313304 -0.39101435\n#> 4 303 -0.52064707  0.84403232\n#> 5 304  1.42813472  0.07150436\n#> 6 305 -0.19044804 -0.84504226\nhead(as.rspec(fakedat, whichwl = \"wavelength\"))#> The spectral data contain 443 negative value(s),\n#>  which may produce unexpected results if used in models.\n#> Consider using procspec() to correct them.#>    wl       refl1       refl2\n#> 1 300 -0.03289339  0.50596119\n#> 2 301 -0.19068789 -1.07089518\n#> 3 302 -0.44313304 -0.39101435\n#> 4 303 -0.52064707  0.84403232\n#> 5 304  1.42813472  0.07150436\n#> 6 305 -0.19044804 -0.84504226\nfakedat.new2 <- as.rspec(fakedat, lim = c(300, 500))#> wavelengths found in column 3#> The spectral data contain 231 negative value(s),\n#>  which may produce unexpected results if used in models.\n#> Consider using procspec() to correct them.\nplot(refl1 ~ wl, type = \"l\", data = fakedat.new2)\nfakedat.new2 <- as.rspec(fakedat, lim = c(300, 1000))#> wavelengths found in column 3#> Warning: Interpolating beyond the range of actual data.\n#> Check 'lim' and `exceed.range` arguments to confirm this is the desired behaviour.#> The spectral data contain 743 negative value(s),\n#>  which may produce unexpected results if used in models.\n#> Consider using procspec() to correct them.\nplot(fakedat.new2[, 2] ~ fakedat.new2[, 1], type = \"l\")"},{"path":"importing-processing-and-visualising-data.html","id":"simulating-spectra","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.1.3 Simulating spectra","text":"version 2.9.0 pavo also introduced function simulate_spec(), allows simple flexible simulation naturalistic spectra. arguments allows us specify sigmoidal (s-shaped) /Gaussian (bell-shaped) features, can combined like simulate suite biological processes.example, might simulate spectrum single Gaussian peak 500 nm, might seen various structural colours, even absorbance visual pigments.complex example include single sigmoidal peak, multiple Gaussian peaks, one spectrum.Finally, might simulate set Gaussian reflectance curves peaks varying 400-600 nm. approach useful various simulation-based studies seek, example, explore optimal receptor sets, constraints colour signal production perception.","code":"\nspec_gauss <- simulate_spec(wl_peak = 400)\nplot(spec_gauss)\nspec_multi <- simulate_spec(wl_inflect = 575, wl_peak = c(340, 430), width_gauss = c(20, 60))\nplot(spec_multi)\npeaks <- seq(400, 600, 10) # Peak locations\nspecs_varying <- lapply(seq_along(peaks), function(x) simulate_spec(wl_peak = peaks[x])) # Simulate spectra\nspecs_varying <- Reduce(merge, specs_varying) # Combine\nplot(specs_varying) # Plot"},{"path":"importing-processing-and-visualising-data.html","id":"subsetting-and-merging-spectral-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.1.4 Subsetting and Merging Spectral Data","text":"rspec object created, either importing raw spectral data, converting dataset .rspec() function, simulation, can subset spectra based names using modified version R’s built-subset function. example, following code illustrates create rspec object containing tanagers:subset function using partial matching find spectra string “tanager” name. fully benefit flexible subsetting functionality, important follow consistent file naming scheme. example, tanager.14423.belly.001.ttt indicate species (tanager), individual ID (14423), body patch (belly) measurement number (001). Additionally, suggest labels used number characters, simplifies character string manipulation subsetting based partial matching.prefer use partial matching, subset also work provide logical condition, similar default subset behaviour R. example:Note subset also work visual model (class vismodel) colspace (class colspace) objects, described .Another useful function merge. Let’s say subsetted spectra tanagers parakeets, like re-combine analysis. following lines code show :Note re-combined file (specs.new) single wl column merged spectra columns. Keep mind order objects merge determine order columns final merged object (.e. tanagers parakeets).","code":"\nspecs.tanager1 <- subset(specs, \"tanager\")\n\nhead(specs.tanager1)[1:5]#>    wl tanager.0001 tanager.0002 tanager.0003 tanager.0004\n#> 1 300      10.0618      10.6744      10.1499      13.7473\n#> 2 301      11.1472      10.8054       9.8003      14.3102\n#> 3 302      10.7819      10.6134       9.5607      14.4463\n#> 4 303      11.0210      11.2037      10.4107      15.5533\n#> 5 304      10.2177      11.2120       9.9452      14.3841\n#> 6 305      11.5664      11.6135      10.8659      15.6445\n# extract first component of filenames containing species names\nspp <- do.call(rbind, strsplit(names(specs), \"\\\\.\"))[, 1]\n\n# subset\nspecs.tanager2 <- subset(specs, subset = spp == \"tanager\")\n\n# compare subsetting methods\nall.equal(specs.tanager1, specs.tanager2)#> [1] TRUE\nspecs.tanager <- subset(specs, \"tanager\")\nspecs.parakeet <- subset(specs, \"parakeet\")\nspecs.new <- merge(specs.tanager, specs.parakeet)"},{"path":"importing-processing-and-visualising-data.html","id":"processing-spectral-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.2 Processing Spectral Data","text":"","code":""},{"path":"importing-processing-and-visualising-data.html","id":"averaging-spectra","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.2.1 Averaging Spectra","text":"previously described, data (contained specs object) consists multiple individuals, measured three times, common avoid measurement bias. good way visualize repeatability measurements plot spectra individual separately. function explorespec() provides easy way . may specify number spectra plotted panel using argument specreps, function adjust number panels per page accordingly. exemplify function using 12 cardinal individuals measured:\nFigure 2.1: Result explorespec, showing three measurements individual cardinal separate panels\nfirst step take average three measurements obtain average individual spectra used analyses. easily accomplished using aggspec() function. argument can either number (specifying many specs averaged new sample) vector specifying identities spectra combined (see ):Now ’ll use aggspec() function , time take average spectrum species. However, species different number samples, can’t use argument . Instead use regular expressions create species name\nvector removing numbers identify individual spectra:Instead, going use spp vector created tell aggspec() function average spectra mspecs:","code":"\n# 36 spectra plus the first (wl) column\nexplorespec(specs[, 1:37], by = 3, lwd = 2)\nmspecs <- aggspec(specs, by = 3, FUN = mean)\nmspecs[1:5, 1:4]#>    wl cardinal cardinal.1 cardinal.2\n#> 1 300 7.292933   5.676700   6.387233\n#> 2 301 7.759200   5.806700   6.698200\n#> 3 302 7.959333   5.858467   6.910500\n#> 4 303 7.947133   6.130267   7.357567\n#> 5 304 8.218200   6.127933   7.195267\n# Data now has 71 spectra,\n# one for each individual,\n# and the 'wl' column\ndim(mspecs)#> [1] 401  72\n# create a vector with species identity names\nspp <- gsub(\"\\\\.[0-9].*$\", \"\", names(mspecs))[-1]\ntable(spp)#> spp\n#> cardinal   jacana   oriole parakeet    robin  tanager \n#>       12        9        9       13       10       18\nsppspec <- aggspec(mspecs, by = spp, FUN = mean)\nround(sppspec[1:5, ], 2)#>    wl cardinal jacana oriole parakeet robin tanager\n#> 1 300     7.05   7.33   3.89     7.63  3.98    9.02\n#> 2 301     7.25   7.35   3.91     7.75  3.91    9.53\n#> 3 302     7.44   7.45   4.13     7.89  4.19    9.41\n#> 4 303     7.82   8.09   4.39     8.49  4.51   10.20\n#> 5 304     7.84   7.71   4.18     8.66  4.07    9.68"},{"path":"importing-processing-and-visualising-data.html","id":"normalizing-and-smoothing-spectra","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.2.2 Normalizing and Smoothing Spectra","text":"Data obtained spectrometers often requires processing analysis /publication. example, electrical noise can produce unwanted “spikes” reflectance curves. pavo function procspec() can handle variety processing techniques. example, reflectance curve parakeet noisy short (300-400 nm) long (650-700 nm) wavelength ranges (see Figure , black line). eliminate noise, use local regression smoothing implemented loess.smooth() function R, wrapped opt=\"smooth\" argument procspec().first, let’s use plotsmooth() function determine suitable smoothing parameter (span). function allows set minimum maximum smoothing parameter try plots resulting curves unsmoothed (raw) data convenient multipanel figure.resulting plot, can see span = 0.2 minimum amount smoothing remove spectral noise preserving original spectral shape. Based value, now use opt argument procspec() smooth data plotting analysis.\nFigure 2.2: Result raw (grey line) smoothed (red line) reflectance data parakeet\ncan also try different normalisations. Options include subtracting minimum reflectance spectrum wavelengths (effectively making minimum reflectance equal zero, opt = \"min\", left panel, ) making reflectance wavelength proportional maximum reflectance (.e. setting maximum reflectance 1; opt = \"max\", centre panel, ). Note user can specify multiple processing options applied sequentially spectral data procspec() (right panel, ).\nFigure 2.3: Results min (left), max (centre), normalisations (right)\n","code":"\nplotsmooth(sppspec,\n  minsmooth = 0.05,\n  maxsmooth = 0.5,\n  curves = 4,\n  ask = FALSE\n)\nspec.sm <- procspec(sppspec, opt = \"smooth\", span = 0.2)#> processing options applied:\n#> smoothing spectra with a span of 0.2\nplot(sppspec[, 5] ~ sppspec[, 1],\n  type = \"l\", lwd = 10, col = \"grey\",\n  xlab = \"Wavelength (nm)\", ylab = \"Reflectance (%)\"\n)\nlines(spec.sm[, 5] ~ sppspec[, 1], col = \"red\", lwd = 2)\n# Run some different normalisations\nspecs.max <- procspec(sppspec, opt = \"max\")#> processing options applied:\n#> Scaling spectra to a maximum value of 1\nspecs.min <- procspec(sppspec, opt = \"min\")#> processing options applied:\n#> Scaling spectra to a minimum value of zero\nspecs.str <- procspec(sppspec, opt = c(\"min\", \"max\")) # multiple options#> processing options applied:\n#> Scaling spectra to a minimum value of zero\n#> Scaling spectra to a maximum value of 1\n# Plot results\nplot(specs.min[, 5] ~ c(300:700),\n  xlab = \"\",\n  ylab = \"\",\n  type = \"l\"\n)\nabline(h = 0, lty = 2)\n\nplot(specs.max[, 5] ~ c(300:700),\n  ylim = c(0, 1),\n  xlab = \"\",\n  ylab = \"\",\n  type = \"l\"\n)\nabline(h = c(0, 1), lty = 2)\n\nplot(specs.str[, 5] ~ c(300:700),\n  type = \"l\",\n  xlab = \"\",\n  ylab = \"\"\n)\nabline(h = c(0, 1), lty = 2)\n\nmtext(\"Wavelength (nm)\", side = 1, outer = TRUE, line = 1)\nmtext(\"Normalised reflectance (%)\", side = 2, outer = TRUE, line = 1)"},{"path":"importing-processing-and-visualising-data.html","id":"binning-and-pca-analysis-of-spectral-shape","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.2.3 Binning and PCA Analysis of Spectral Shape","text":"Another intended usage procspec() preparation spectral data dimensionality reduction (example, using Principal Component Analysis, PCA). Following Cuthill et al. (1999), can use opt = 'center' centre spectra mean reflectance zero (thus removing brightness dominant variable PCA) bin spectra user-defined bins (using opt = 'bin' argument) obtain dataframe suitable PCA.can seen summary, PC1 explains approximately 64% variation spectral shape describes ratio short long wavelengths reflected. flexibility R pavo’s plotting capabilities allows sort spectra another variable (e.g., PC1 loading) plot stacked format using plot function.\nFigure 2.4: Plot PC1 loading versus wavelength (left) species mean spectra sorted vertically lowest highest PC1 value (right; values right hand axis column identities).\n","code":"\n# PCA analysis\nspec.bin <- procspec(sppspec, opt = c(\"bin\", \"center\"))#> processing options applied:\n#> Centering spectra to a mean of zero\n#> binned spectra to 21-nm intervals\nhead(spec.bin)#>    wl   cardinal    jacana    oriole  parakeet      robin\n#> 1 300 -12.991747 -15.98282 -17.78389 -5.187601 -10.043001\n#> 2 321  -8.754302 -15.22013 -15.67409 -3.497942  -9.751455\n#> 3 342  -5.490538 -14.60414 -14.58129 -3.695973  -9.454188\n#> 4 363  -4.639077 -14.17163 -15.03655 -5.552378  -9.222658\n#> 5 384  -5.563199 -14.48320 -16.68218 -7.387742  -8.880768\n#> 6 405  -8.639736 -14.92472 -17.86635 -8.574752  -8.326391\n#>       tanager\n#> 1 -9.61852071\n#> 2 -6.74685034\n#> 3 -2.77517997\n#> 4 -0.14415405\n#> 5 -0.03173553\n#> 6 -1.44428182\n# Transpose so wavelength are variables for the PCA\nspec.bin <- t(spec.bin)\n\n# Names variables as wavelength bins\ncolnames(spec.bin) <- spec.bin[1, ]\nspec.bin <- spec.bin[-1, ] # remove 'wl' column\npca1 <- prcomp(spec.bin, scale. = TRUE)\nsummary(pca1)#> Importance of components:\n#>                           PC1    PC2    PC3    PC4     PC5\n#> Standard deviation     3.6016 1.9885 1.5791 0.6678 0.36656\n#> Proportion of Variance 0.6486 0.1977 0.1247 0.0223 0.00672\n#> Cumulative Proportion  0.6486 0.8463 0.9710 0.9933 1.00000\n#>                              PC6\n#> Standard deviation     4.411e-16\n#> Proportion of Variance 0.000e+00\n#> Cumulative Proportion  1.000e+00\n# Generate colours from spectra\ncolr <- spec2rgb(sppspec)\nwls <- as.numeric(colnames(spec.bin))\n\n# Rank specs by PC1\nsel <- rank(pca1$x[, 1])\nsel <- match(names(sort(sel)), names(sppspec))\n\n# Plot results\nplot(pca1$rotation[, 1] ~ wls, type = \"l\", ylab = \"PC1 loading\")\nabline(h = 0, lty = 2)\nplot(sppspec,\n  select = sel,\n  labels.stack = names(sppspec)[sel],\n  type = \"s\",\n  col = colr\n)\nmtext(\"Wavelength (nm)\", side = 1, outer = TRUE, line = 1)"},{"path":"importing-processing-and-visualising-data.html","id":"dealing-with-negative-values-in-spectra","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.2.4 Dealing With Negative Values in Spectra","text":"Negative values spectra unwanted, uninterpretable (can less zero light reflected surface?) can affect estimates colour variables. Nonetheless, certain spectrometer manufacturers allow negative values saved. handle negative values, procspec() function argument called fixneg. two options available (1) adding absolute value negative value whole spectrum addmin, (2) changing negative values zero zero.\nFigure 2.5: Plots showing original reflectance curve including negative values (left) two processed curves using fixneg = addmin (center) fixneg = zero (right).\nmanipultions may different effects final spectra, user keep mind use according final goal analysis. example, adding minimum reflectance wavelength, shape curve preserved, maximum reflectance much higher. hand, substituting negative values zero preserves absolute reflectance values, may cause spectral shape lost. “best” transformation depend severity problem negative values goal analysis (e.g. reflectance intensity used? important, preserve reflectance values total shape curve?). correction use also depend source negative values. thought originate improper calibration spectrophotometer, fixneg = addmin appropriate. However, thought originate electric noise, fixneg = zero appropriate.","code":"\n# Create a duplicate spectrum and add some negative values\nrefl <- sppspec[, 7] - 20\ntestspecs <- as.rspec(cbind(c(300:700), refl))#> wavelengths found in column 1#> The spectral data contain 188 negative value(s),\n#>  which may produce unexpected results if used in models.\n#> Consider using procspec() to correct them.\n# Apply two different processing options\ntestspecs.fix1 <- procspec(testspecs, fixneg = \"addmin\")#> processing options applied:\n#> Negative value correction: added min to all reflectance\ntestspecs.fix2 <- procspec(testspecs, fixneg = \"zero\")#> processing options applied:\n#> Negative value correction: converted negative values to zero\n# Plot it\nplot(testspecs, select = 2, ylim = c(-10, 30))\nabline(h = 0, lty = 3)\n\nplot(testspecs.fix1, select = 2, ylim = c(-10, 30))\nabline(h = 0, lty = 3)\n\nplot(testspecs.fix2, select = 2, ylim = c(-10, 30))\nabline(h = 0, lty = 3)\n\nmtext(\"Wavelength (nm)\", side = 1, outer = TRUE, line = 1)\nmtext(\"Reflectance (%)\", side = 2, outer = TRUE, line = 1)"},{"path":"importing-processing-and-visualising-data.html","id":"visualizing-spectral-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.3 Visualizing Spectral Data","text":"pavo offers three main plotting functions. main one plot, combines several different options flexible framework commonly used purposes. explorespec() function aims providing initial exploratory analysis, demonstrated Section 1. Finally, aggplot() provides simple framework publication-quality plots aggregated spectral data.","code":""},{"path":"importing-processing-and-visualising-data.html","id":"the-plot-function-options","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.3.1 The plot Function Options","text":"Since pavo uses class rspec identify spectral data, function plot.rspec() can called simply calling plot(data). object class rspec multivariate visualisation methods work expected, might useful check data using .rspec() convert .rspec() necessary.implemented three methods visualizing spectral data using plot:Overlay: spectra plotted x- y-axisStack: spectra plotted x-axis arranged vertically along y-axisHeatmap: false colour map illustrate three dimensional dataThese options addition exploratory plotting offered explorespec(), seen figures section 1. showcase capabilities plot.rspec(), use teal dataset included pavo. dataset consists reflectance spectra iridescent wing patch green-winged teal (Anas carolinensis). Reflectance measurements taken 300 700 nm different incident angles, ranging 15° 70° (5° increments) (Eliason Shawkey 2012).\nFigure 2.6: Anas carolinensis, pixabay user Cock-Robin, CC0\n","code":""},{"path":"importing-processing-and-visualising-data.html","id":"the-overlay-option","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.3.1.1 The overlay Option","text":"can start visualizing spectra overlay option plot. Another neat option pavo offers convert reflectance spectra approximate perceived colour, using function spec2rgb(). can make interesting plots even exploratory data analysis, shown .\nFigure 2.7: Overlay plot teal angle-dependent reflectance colours curve approximation perceived colour.\n","code":"\ndata(teal)\nplot(teal, type = \"o\", col = spec2rgb(teal))"},{"path":"importing-processing-and-visualising-data.html","id":"the-stack-option","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.3.1.2 The stack Option","text":"Another option stack plot (, human vision approximations colour produced spectra using spec2rgb()).\nFigure 2.8: Stacked plot raw (left) normalized (right) teal angle-dependent reflectance\nNote figure, y axis right includes index spectrum. makes easier identify subset specific spectra groups spectra using select argument plot.rspec(). Note also first index actually 2, preserving sequence original dataset (since first column wavelength). Though may seem confusing first (“first spec number 2?”) preserves subsetting hierarchy: using plot(teal, select = 2) show spectra selected use teal[ ,2].","code":"\nteal.norm <- procspec(teal, opt = c(\"min\", \"max\"))#> processing options applied:\n#> Scaling spectra to a minimum value of zero\n#> Scaling spectra to a maximum value of 1\nplot(teal, type = \"s\", col = spec2rgb(teal))\nplot(teal.norm, type = \"s\", col = spec2rgb(teal))\n\nmtext(\"Wavelength (nm)\", side = 1, outer = TRUE, line = 1)\nmtext(\"Cumulative reflectance (A.U.)\", side = 2, outer = TRUE, line = 1)"},{"path":"importing-processing-and-visualising-data.html","id":"the-heatmap-option","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.3.1.3 The heatmap Option","text":"Since dataset three-dimensional (containing wavelengths, reflectance values incident angles) can also use heatmap function. First, necessary define vector incident angles spectrum measured :Next, smooth data procspec() plot false colour map (heatmap):\nFigure 2.9: Heatmap plot angle-resolved reflectance measurements green-winged teal.\nplots can useful observe changes time, example, type continuous variation.","code":"\nangles <- seq(15, 70, by = 5)\n# Smooth the spectral data\nteal.sm <- procspec(teal, opt = c(\"smooth\"))#> processing options applied:\n#> smoothing spectra with a span of 0.25\n# Plot it as a heatmap\nplot(teal.sm,\n  type = \"h\", varying = angles,\n  ylab = expression(paste(\"Incident angle (\", degree, \")\")),\n  las = 1, useRaster = TRUE\n)"},{"path":"importing-processing-and-visualising-data.html","id":"the-aggplot-function","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.3.2 The aggplot() Function","text":"aggplot() similar interface aggspec(), allowing quick plotting aggregated spectra combined factor, species, sex, experimental treatment, . main output plot lines group mean spectra outlined shaded area indicating measure variability, standard deviation group. Note functions aren’t already implemented R must passed like functions apply (e.g., function(x) sd(x)/sqrt(length(x)) example ).\nFigure 2.10: Example plots created using aggplot. Left: using median, standard deviation, coloured lines. Right: using mean, standard error, greyscale\n","code":"\n# Plot using median and standard deviation, default colours\naggplot(mspecs, spp,\n  FUN.center = median,\n  ylim = c(0, 70),\n  alpha = 0.3, legend = TRUE\n)\n\n# Plot using mean and standard error, in greyscale\naggplot(mspecs, spp,\n  ylim = c(0, 70),\n  FUN.error = function(x) sd(x) / sqrt(length(x)),\n  lcol = 1, shadecol = \"grey\", alpha = 0.7\n)"},{"path":"importing-processing-and-visualising-data.html","id":"organizing-spatial-image-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.4 Organizing Spatial (image) Data","text":"first import images getimg(), functions similar manner getspec(). Since importing one image, can simply point function folder containing images, use parallel processing (possible) import jpg, bmp, png images folder. raw spectra, images also available package repository [][data-location], included package installation convenience.pavo imports images, created multidimensional object class rimg, inherits array class. one image imported, rimg objects stored elements list. image-based functions pavo capable working rimg lists, allows convenient tidy high-throughput workflow. Note pavo allow load, manipulate, analyse many images computer’s memory allows, throw message total size images memory greater ca. 200mb, result noticeably slowed performance (everything still work, just slow). may ameliorated reducing size individual images, procimg(), processing images smaller batches. rimg objects number identifying attributes, drawn image-processing functions, can readily inspected.already images loaded R, can convert rimg objects using .rimg(). function attempt interpret multidimensional array RGB image values ranging [0, 1], imbue custom attributes rimg. can see creating fake array, converting .","code":"\nbutterflies <- getimg(system.file(\"testdata/images/butterflies\",\n  package = \"pavo\"\n))#> 2 files found; importing images.\nis.rimg(butterflies)#> [1] TRUE\nstr(butterflies[[1]])#>  'rimg' num [1:500, 1:340, 1:3] 1 1 1 1 1 1 1 1 1 1 ...\n#>  - attr(*, \"state\")= chr \"raw\"\n#>  - attr(*, \"imgname\")= chr \"h_melpomene\"\n#>  - attr(*, \"px_scale\")= logi NA\n#>  - attr(*, \"raw_scale\")= logi NA\n#>  - attr(*, \"k\")= logi NA\n#>  - attr(*, \"outline\")= logi NA\n#>  - attr(*, \"colnames\")= logi NA\n#>  - attr(*, \"tag_loc\")= logi NA\nstr(butterflies[[2]])#>  'rimg' num [1:500, 1:398, 1:3] 1 1 1 1 1 1 1 1 1 1 ...\n#>  - attr(*, \"state\")= chr \"raw\"\n#>  - attr(*, \"imgname\")= chr \"papilio\"\n#>  - attr(*, \"px_scale\")= logi NA\n#>  - attr(*, \"raw_scale\")= logi NA\n#>  - attr(*, \"k\")= logi NA\n#>  - attr(*, \"outline\")= logi NA\n#>  - attr(*, \"colnames\")= logi NA\n#>  - attr(*, \"tag_loc\")= logi NA\nfakeimg <- array(\n  c(\n    matrix(c(1, 1, 0, 0), nrow = 12, ncol = 8),\n    matrix(c(0, 0, 0, 0), nrow = 12, ncol = 8),\n    matrix(c(0, 0, 1, 1), nrow = 12, ncol = 8)\n  ),\n  dim = c(12, 8, 3)\n)\nfake_rimg <- as.rimg(fakeimg)\nis.rimg(fake_rimg)#> [1] TRUE\nstr(fake_rimg)#>  'rimg' num [1:12, 1:8, 1:3] 1 1 0 0 1 1 0 0 1 1 ...\n#>  - attr(*, \"state\")= chr \"raw\"\n#>  - attr(*, \"imgname\")= chr \"img\"\n#>  - attr(*, \"px_scale\")= logi NA\n#>  - attr(*, \"raw_scale\")= logi NA\n#>  - attr(*, \"k\")= logi NA\n#>  - attr(*, \"outline\")= logi NA\n#>  - attr(*, \"colnames\")= logi NA\n#>  - attr(*, \"tag_loc\")= logi NA"},{"path":"importing-processing-and-visualising-data.html","id":"visualising-image-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.5 Visualising Image Data","text":"","code":""},{"path":"importing-processing-and-visualising-data.html","id":"the-plot-and-summary-functions","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.5.1 The plot and summary Functions","text":"Thanks underlying class system pavo, generic functions plot summary recognise respond image-data appropriate manner, case spectral data. quick call plot, example, prints images. Note call image individually (convenient printing vignette), simply feed entire list images plot automatically step image list upon user input.\nFigure 2.11: Raw images butterflies\nsummary function offers summary information images lists images might expect. specify plot = TRUE however, function instead plots image. images colour-classified also plots images’ colour palette alongside (see ). extremely useful diagnostic tool classifying images, allows us see well classification algorithm performed clustering colour pattern elements discrete colour categories. plots, function takes standard plot arguments (see ?par), custom colours, can diagnostically useful.","code":"\n# Note the plot titles are taken\n# from the file names, and can be overridden.\npar(mfrow = c(1, 2))\nplot(butterflies[[1]])\nplot(butterflies[[2]])"},{"path":"importing-processing-and-visualising-data.html","id":"processing-image-data","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.6 Processing Image Data","text":"","code":""},{"path":"importing-processing-and-visualising-data.html","id":"overview","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.6.1 Overview","text":"Images often require post-capture processing, depending intended use, pavo offers useful options via procimg(). functionality procimg() currently limited closely relevant analyses currently implemented, assume major processing quality-checking (e.g. image rotation colour correction) undertaken user beforehand. However, users keep image processing within R ecosystem, now exist several excellent image-processing packages imager magick, pavo can seamlessly work . Indeed, functions rimg2cimg() rimg2magick() convert images pavo preferred structure used imager (reverse simply achieved via .rimg()), simplifies transitions packages.","code":""},{"path":"importing-processing-and-visualising-data.html","id":"filtering-images-to-model-the-visual-acuity-of-animals","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.6.2 Filtering images to model the visual acuity of animals","text":"resolving power animals large part defined visual acuity, reality important consequences questions signal evolution visual ecology. process can can now accounted (part) via procimg() implements AcuityView algorithm Caves Johnson (2018). Note users familiar algorithm 2.0 implementation, now accepts rectangular images (square dimensions power 2).run procedure, procimg() requires three arguments: obj_dist, real-world distance viewer focal object image, obj_width, real-world width entire image, eye_res, resolution viewer degrees. units measurement suitable obj_dist obj_width, must match. ’ll run butterfly images process assuming conspecific viewer distance 60 cm, image width 10 cm, visual acuity 0.2 CPD.\nFigure 2.12: Images butterflies modelling acuity conspecific viewer\nNote important considerations caveats method. core publication Caves Johnsen (2018) provides rich discussion points (course also cited whenever used). brief, however, remembered :AcuityView allows us gain insight spatial information can detected viewer, converted image animal actually sees. experimental theoretical treatment can provide much insight perceptual world another animal.converted image account edge enhancement processing retina brain can sharpen (add detail) image. converted image also static, allow one assess movement may reveal presence otherwise indiscernible object.AcuityView algorithm makes several assumptions modulation transfer function (MTF). First, assumes MTF constant region eye views scene, scene interest viewed portion retina highest acuity (e.g. fovea). also assumes MTF circularly symmetrical, always true. eyes non-circular PSFs can lead non-circular MTFs (e.g. Baldwin Fergus et al., 2015). Finally, assumes MTF wavelength-independent, whereas MTF strongly affected light scattering may exhibit dependence wavelength result. Note greater flexibility specifying MTF implemented future, feel free get touch required shorter term.","code":"\n# Model the appearance of our butterflies given the reduced\n# visual acuity of another animal viewer as per the\n# AcuityView 2.0 algorithm (Caves & Johnsen 2018). Here\n# our butterfly is 60 cm away, the image width is 10 cm,\n# and the spatial resolution of the viewer is 0.2-degrees.\nbutterflies_acuity <- procimg(butterflies,\n  obj_dist = 60,\n  obj_width = 10,\n  eye_res = 0.2\n)\n\n# See the results\npar(mfrow = c(1, 2))\nplot(butterflies_acuity[[1]])\nplot(butterflies_acuity[[2]])"},{"path":"importing-processing-and-visualising-data.html","id":"setting-scales-and-defining-objects","chapter":"2 Importing, Processing, and Visualising Data","heading":"2.6.3 Setting Scales and Defining Objects","text":"central purpose procimg() centres rotating resizing images, setting real-world image scale, /distinguishing focal object background. Rotating image simply requires inputting angle, degrees, image rotated centre, resizing requires scaling factor size image(s) decreased increased. Setting scales distinguishing backgrounds, contrast, interactive procedures, meaning presented focal image must select points using mouse (either line, setting scale, polygon identifying focus). setting scale, specify scale preferred units via scaledist, click endpoints scale within image (‘formal’ scale, simply length wing another known reference object). information, usual, attached image attribute.Distinguishing focal object background important cases analysing broader visual scene, particularly background highly heterogeneous, animal nature, classified homogeneous block identified simply (see ). define object background specify outline = TRUE, result asked click around outline focal object image, converted polygon — xy coordinates saved attribute. often useful slightly smooth resulting polygon, can done Chaikin’s corner-cutting algorithm specifying number refinements. Chaikin’s algorithm works iteratively replacing every point two new points 1/4 way next. argument iterations specifies number corner cutting iterations apply, default value 1 offers subtle smoothing effect.options can simultaneously specified single call procimg(), pavo 2.0 publication offers useful example processing, since involved features difficult illustrate due interactive nature.","code":"\n# Interactively specify the real-world scale of the image.\n# Here 100 mm.\nbutterflies <- procimg(butterflies, scaledist = 100)\n# Interactively specify a smoothed polygon\n# around the focal objects\nbutterflies <- procimg(butterflies,\n  outline = TRUE,\n  iterations = 1\n)"},{"path":"analysing-data.html","id":"analysing-data","chapter":"3 Analysing Data","heading":"3 Analysing Data","text":"Let’s begin loading package.","code":"\n# Load the package, and set a global random-number seed\n# for the reproducible generation of fake data later on.\nlibrary(pavo)\nset.seed(1612217)"},{"path":"analysing-data.html","id":"analysing-spectral-data","chapter":"3 Analysing Data","heading":"3.1 Analysing Spectral Data","text":"","code":""},{"path":"analysing-data.html","id":"spectral-dataset-description-1","chapter":"3 Analysing Data","heading":"3.1.1 Spectral Dataset Description","text":"raw spectral data used example available package repository github, located . can download extract follow vignette exactly. Alternatively, data included RData file part package installation, can loaded directly (see ).data consist reflectance spectra, obtained using Avantes equipment software, seven bird species: Northern Cardinal Cardinalis cardinalis, Wattled Jacana Jacana jacana, Baltimore Oriole Icterus galbula, Peach-fronted Parakeet Aratinga aurea, American Robin Turdus migratorius, Sayaca Tanager Thraupis sayaca. Several individuals measured (sample size varies species), 3 spectra collected individual. However, number individuals measured per species uneven data additional peculiarities emphasize flexibility pavo offers, ’ll see .addition, pavo includes three datasets can called data function. data(teal), data(sicalis), data(flowers) used vignette. See help files dataset information; via ?teal, ?sicalis, ?flowers.","code":"\nspecs <- readRDS(system.file(\"extdata/specsdata.rds\",\n  package = \"pavo\"\n))\nmspecs <- aggspec(specs, by = 3, FUN = mean)\nspp <- gsub(\"\\\\.[0-9].*$\", \"\", names(mspecs))[-1]\nsppspec <- aggspec(mspecs, by = spp, FUN = mean)\nspec.sm <- procspec(sppspec, opt = \"smooth\", span = 0.2)#> processing options applied:\n#> smoothing spectra with a span of 0.2"},{"path":"analysing-data.html","id":"overview-1","chapter":"3 Analysing Data","heading":"3.1.2 Overview","text":"pavo offers two main approaches spectral data analysis. First, colour variables can calculated based shape reflectance spectra. using special R classes spectra data frame objects, can easily done using summary function rspec object (see ). function peakshape() also returns descriptors individual peaks spectral curves, outlined .Second, reflectance spectra can analysed accounting visual system receiving colour signal, therefore representing reflectance spectra perceived colours. end, implemented suite visual models colourspaces including; receptor-noise limited model model Vorobyev et al. (1998), Endler (1990)’s segment classification method, flexible di- tri- tetra-chromatic colourspaces, Hexagon model Chittka (1992), colour-opponent coding space Backhaus (1991), CIELAB CIEXYZ spaces, categorical model Troje (1993).","code":""},{"path":"analysing-data.html","id":"spectral-shape-analysis","chapter":"3 Analysing Data","heading":"3.1.3 Spectral Shape Analysis","text":"","code":""},{"path":"analysing-data.html","id":"colourimetric-variables","chapter":"3 Analysing Data","heading":"3.1.3.1 Colourimetric Variables","text":"Obtaining colourimetric variables (pertaining hue, saturation brightness/value) pretty straightforward pavo. Since reflectance spectra stored object class rspec, summary function recognizes object extracts 23 variables, outlined Montgomerie (2006) (reproduced ). Though outlined book chapter bird colouration, variables broadly applicable reflectance data, particularly taxon interest colour vision within UV-human visible range.description formulas variables can found running ?summary.rspec.summary also takes additional argument subset changed default FALSE TRUE return commonly used colourimetrics (Andersson Prager 2006). summary can also take vector colour variable names, can used filter results","code":"\nsummary(spec.sm)#>                B1       B2       B3        S1U        S1V\n#> cardinal 8984.266 22.40465 52.70167 0.16614848 0.19110215\n#> jacana   9668.503 24.11098 53.78744 0.09601072 0.11022142\n#> oriole   9108.474 22.71440 54.15508 0.07484472 0.08323604\n#> parakeet 6020.733 15.01430 29.86504 0.16792815 0.18501247\n#> robin    5741.392 14.31769 37.85542 0.08503645 0.10014331\n#> tanager  8515.251 21.23504 30.48108 0.20322408 0.23904955\n#>                 S1B       S1G       S1Y       S1R        S2\n#> cardinal 0.11783711 0.1898843 0.2519174 0.5333116  7.607769\n#> jacana   0.19494363 0.3079239 0.2482692 0.4083129  7.101897\n#> oriole   0.05728179 0.3254691 0.3624909 0.5492239 14.507969\n#> parakeet 0.14407795 0.4244676 0.3395961 0.2718894  5.111074\n#> robin    0.14428130 0.2673730 0.2668138 0.5100635  9.130156\n#> tanager  0.26133545 0.3198724 0.2430666 0.2238857  3.226417\n#>                 S3         S4       S5       S6         S7       S8\n#> cardinal 0.2954315 0.20287401 4003.465 45.77432 -0.2055325 2.043072\n#> jacana   0.2471677 0.05315822 3314.024 46.21377 -0.3054756 1.916710\n#> oriole   0.2986678 0.08730015 5233.013 50.42230 -0.5847404 2.219838\n#> parakeet 0.4483808 0.27397999 1894.018 24.02183  0.6656480 1.599931\n#> robin    0.3031501         NA 2532.414 33.70923 -0.1076722 2.354377\n#> tanager  0.3343114 0.16775097 1106.471 21.03373 -0.7851970 0.990520\n#>                   S9       S10  H1  H2  H3         H4  H5\n#> cardinal  0.83791691 0.4144862 700 419 587 0.02130606 581\n#> jacana    0.73309578 0.1018889 700 593 529 0.71519543 468\n#> oriole    0.92483219 0.1937922 700 382 551 0.41436251 544\n#> parakeet  0.58642273 0.4383490 572 618 634 0.97835569 506\n#> robin     0.81473611        NA 700  NA 593 0.42040115 631\n#> tanager  -0.04551277 0.1661607 557 594 362 1.52666571 518\nsummary(spec.sm, subset = TRUE)#>                B2       S8  H1\n#> cardinal 22.40465 2.043072 700\n#> jacana   24.11098 1.916710 700\n#> oriole   22.71440 2.219838 700\n#> parakeet 15.01430 1.599931 572\n#> robin    14.31769 2.354377 700\n#> tanager  21.23504 0.990520 557\n# Extract only brightness variables\nsummary(spec.sm, subset = c(\"B1\", \"B2\", \"B3\"))#>                B1       B2       B3\n#> cardinal 8984.266 22.40465 52.70167\n#> jacana   9668.503 24.11098 53.78744\n#> oriole   9108.474 22.71440 54.15508\n#> parakeet 6020.733 15.01430 29.86504\n#> robin    5741.392 14.31769 37.85542\n#> tanager  8515.251 21.23504 30.48108"},{"path":"analysing-data.html","id":"peak-shape-descriptors","chapter":"3 Analysing Data","heading":"3.1.3.2 Peak Shape Descriptors","text":"Particularly cases reflectance spectra multiple discrete peaks (case summary function return variables based tallest peak curve), might useful obtain variables describe individual peak’s properties. peakshape() function identifies peak location (H1), returns reflectance point (B3), identifies wavelengths reflectance half peak, calculating wavelength bandwidth interval (Full Width Half Maximum, FWHM). function also returns half widths, useful peaks located near edge measurement limit half maximum reflectance can reliably estimated one sides.sounds esoteric, fear : peakshape() option returning plots indicating ’s calculating. vertical continuous red line indicates peak location, horizontal continuous red line indicates half-maximum reflectance, distance dashed lines (HWHM.l HWHM.r) FWHM:\nFigure 3.1: Plots peakshape\ncan seen, variable FWHM meaningless curve doesn’t clear peak. Sometimes, case Cardinal (figure, first panel), might peak point maximum reflectance entire spectral curve. peakshape() also offers select argument facilitate subsetting spectra data frame , example, focus single reflectance peak:\nFigure 3.2: Plot peakshape, setting wavelength limits 300 500 nm\n","code":"\npeakshape(spec.sm, plot = TRUE)#>         id       B3  H1 FWHM HWHM.l HWHM.r incl.min\n#> 1 cardinal 52.70167 700   NA    114     NA      Yes\n#> 2   jacana 53.78744 700   NA    172     NA      Yes\n#> 3   oriole 54.15508 700   NA    149     NA      Yes\n#> 4 parakeet 29.86504 572  126     63     63      Yes\n#> 5    robin 37.85542 700   NA    107     NA      Yes\n#> 6  tanager 30.48108 557  166     81     85      Yes\npeakshape(spec.sm, select = 2, lim = c(300, 500), plot = TRUE)#>         id       B3  H1 FWHM HWHM.l HWHM.r incl.min\n#> 1 cardinal 17.84381 369  100     46     54      Yes"},{"path":"analysing-data.html","id":"visual-modelling","chapter":"3 Analysing Data","heading":"3.1.4 Visual Modelling","text":"","code":""},{"path":"analysing-data.html","id":"overview-2","chapter":"3 Analysing Data","heading":"3.1.4.1 Overview","text":"visual colourspace modelling plotting options wrapped four main function: vismodel(), colspace(), coldist() (bootstrap-based variant bootcoldist()), plot. detailed , functions cover basic processes common modelling approaches. Namely, estimation quantum catches, conversion appropriate space, estimating distances samples, visualising results. brief example, typical workflow modelling might use:vismodel() estimate photoreceptor quantum catches. assumptions visual models may differ dramatically, sure select options appropriate intended use.colspace() convert results vismodel() (user-provided quantum catches) points given colourspace, specified space argument. space argument provided, colspace() automatically select di-, tri- tetrahedral colourspace, depending nature input data. result colspace() object class colspace (inherits data.frame), contain location stimuli selected space along associated colour variables.coldist() bootcoldist() estimate colour distances points colourspace (input colspace), ‘perceptual’, noise-weighted distances receptor-noise limited model (input vismodel() relative = FALSE).plot output. plot automatically select appropriate visualisation based input colspace object, also accept various graphical parameters depending colourspace (see ?plot.colspace links therein details).","code":""},{"path":"analysing-data.html","id":"accessing-and-plotting-in-built-spectral-data","chapter":"3 Analysing Data","heading":"3.1.4.2 Accessing and Plotting In-built Spectral Data","text":"-built spectral data pavo can easily retrieved /plotted via sensdata() function. data can visualised directly including plot = TRUE, assigned object subsequent use, :","code":"\nmusca_sense <- sensdata(visual = \"musca\", achromatic = \"md.r1\")\nhead(musca_sense)#>    wl    musca.u     musca.s     musca.m     musca.l       md.r1\n#> 1 300 0.01148992 0.006726680 0.001533875 0.001524705 0.001713692\n#> 2 301 0.01152860 0.006749516 0.001535080 0.001534918 0.001731120\n#> 3 302 0.01156790 0.006773283 0.001536451 0.001545578 0.001751792\n#> 4 303 0.01160839 0.006798036 0.001537982 0.001556695 0.001775960\n#> 5 304 0.01165060 0.006823827 0.001539667 0.001568283 0.001803871\n#> 6 305 0.01169510 0.006850712 0.001541499 0.001580352 0.001835777"},{"path":"analysing-data.html","id":"visual-phenotypes","chapter":"3 Analysing Data","heading":"3.1.4.3 Visual Phenotypes","text":"pavo contains numerous di-, tri- tetrachromatic visual systems, accompany suite new models. full complement included systems accessible via vismodel() argument visual, include:Table 3.1: Built-visual phenotypes available pavo","code":""},{"path":"analysing-data.html","id":"estimating-quantum-catch","chapter":"3 Analysing Data","heading":"3.1.4.4 Estimating Quantum Catch","text":"Numerous models developed understand colours perceived discriminated individual’s species’ visual system (described detail Endler 1990; Renoult, Kelber, Schaefer 2017; Vorobyev et al. 1998). essence, models take account receptor sensitivity different receptors make visual system question quantify given colour stimulate receptors individually, combined effect perception colour. models also important component assuming interpreting chromatic component colour (hue saturation) processed independently achromatic (brightness, luminance) component. provides flexible framework allowing tiered model construction, information aspects different illumination sources, backgrounds, visual systems can considered compared.apply model, first need quantify receptor excitation consider signal processed, possibly considering relative density different cones noise--signal ratio.quantify stimulation receptors given stimulus, use function vismodel(). takes rspec dataframe minimal input, user can either select available options input data additional arguments function:visual: visual system used. Available inbuilt options detailed , user may include dataframe, first column wavelength range following columns absorbance wavelength cone type (see example).achromatic: Either receptor’s sensitivity data (available options include blue tit, chicken, starling double-cones, housefly’s R1-6 receptor), can also user-defined ; longest-wavelength receptor, sum two longest-wavelength receptors, sum receptors can used. Alternatively, none can specified achromatic stimulation calculation.illum: illuminant considered. default, considers ideal white illuminant, implemented options blue sky, standard daylight, forest shade illuminants. vector length wavelength range considered can also used input.trans: Models effects light transmission (e.g. noisy environments ocular filters). argument defaults ideal (.e. effect), though users can also use built-options bluetit blackbird model ocular transmission blue tits/blackbirds, specify user-defined vector containing transmission spectra.qcatch: argument determines photon catch data returned\nQi: receptor quantum catches, calculated receptor \\(\\) :\n\\[Q_i = \\int_\\lambda{R_i(\\lambda)S(\\lambda)(\\lambda)d\\lambda}\\]\n\\(\\lambda\\) denotes wavelength, \\(R_i(\\lambda)\\) spectral sensitivity receptor \\(\\), \\(S(\\lambda)\\) reflectance spectrum colour, \\((\\lambda)\\) illuminant spectrum.\nfi: receptor quantum catches transformed according Fechner’s law, signal receptor proportional logarithm quantum catch .e. \\(f_i = \\ln(Q_i)\\)\nEi: hyperbolic transform (simplification Michaelis–Menten photoreceptor equation), \\[E_i = \\frac{Q_i}{Q_i + 1}\\].\nQi: receptor quantum catches, calculated receptor \\(\\) :\n\\[Q_i = \\int_\\lambda{R_i(\\lambda)S(\\lambda)(\\lambda)d\\lambda}\\]\n\\(\\lambda\\) denotes wavelength, \\(R_i(\\lambda)\\) spectral sensitivity receptor \\(\\), \\(S(\\lambda)\\) reflectance spectrum colour, \\((\\lambda)\\) illuminant spectrum.fi: receptor quantum catches transformed according Fechner’s law, signal receptor proportional logarithm quantum catch .e. \\(f_i = \\ln(Q_i)\\)Ei: hyperbolic transform (simplification Michaelis–Menten photoreceptor equation), \\[E_i = \\frac{Q_i}{Q_i + 1}\\].bkg: background considered. default, considers idealized background (.e. wavelength-independent influence background colour). vector length wavelength range considered can also used input.vonkries: logical argument determines von Kries transformation (normalizes receptor quantum catches background, thus accounting receptor adaptation) applied (defaults FALSE). TRUE, \\(Q_i\\) multiplied constant \\(k\\), describes von Kries transformation: \\[k_i = \\frac{1}{\\int_\\lambda R_i(\\lambda)S^b(\\lambda)(\\lambda)d\\lambda}\\] \\(S^b\\) denotes reflectance spectra background.scale: argument defines illuminant scaled. scale illuminant critical receptor noise models signal intensity influences noise (see Receptor noise section, ). Illuminant curves units \\(\\mu mol.s^{-1}.m^{-2}\\) order yield physiologically meaningful results. (software return illuminant information values \\(\\mu Watt.cm^{-2}\\), must converted \\(\\mu mol.s^{-1}.m^{-2}\\). can done using irrad2flux() flux2irrad() functions.) Therefore, user-specified illuminant curves units (.e. measured proportional white standard, example), scale parameter can used multiplier yield curves least reasonable approximation illuminant value. Commonly used values 500 dim conditions 10,000 bright conditions.relative: TRUE, make cone stimulations relative sum. appropriate general colourspace models(e.g. Goldsmith 1990; Stoddard Prum 2008). receptor-noise model, however, important set relative = FALSE.visual models begin estimation receptor quantum catches. requirements models may differ significantly course, sure consult function documentation original publications. example, use average reflectance different species calculate raw stimulation retinal cones, considering avian average UV visual system, standard daylight illumination, idealized background.Since multiple parameters can used customize output vismodel(), detailed , convenience can returned using summary vismodel object:can visualise vismodel() estimating quantum catches comparing reflectance spectra estimates generating:\nFigure 3.3: Plots species mean reflectance curves corresponding relative usml cone stimulations (insets).\ndescribed , vismodel also accepts user-defined visual systems, background illuminants. illustrate showcasing function sensmodel, models spectral sensitivities retinas based peak cone sensitivity, described Govardovskii et al. (2000) Hart Vorobyev (2005). sensmodel takes several optional arguments, main one vector containing peak sensitivities cones modelled. Let’s model idealized dichromat visual system, cones peaking sensitivity 350 650 nm:\nFigure 3.4: receptor sensitivities idealised dichromat created using sensmodel().\n","code":"\nvismod1 <- vismodel(sppspec,\n  visual = \"avg.uv\", achromatic = \"bt.dc\",\n  illum = \"D65\", relative = FALSE\n)\nsummary(vismod1)#> visual model options:\n#>  * Quantal catch: Qi \n#>  * Visual system, chromatic: avg.uv \n#>  * Visual system, achromatic: bt.dc \n#>  * Illuminant: D65, scale = 1 (von Kries colour correction not applied) \n#>  * Background: ideal \n#>  * Transmission: ideal \n#>  * Relative: FALSE#>        u                 s                 m         \n#>  Min.   :0.01671   Min.   :0.04199   Min.   :0.1325  \n#>  1st Qu.:0.02408   1st Qu.:0.06860   1st Qu.:0.1753  \n#>  Median :0.03039   Median :0.07148   Median :0.2675  \n#>  Mean   :0.03599   Mean   :0.09924   Mean   :0.2338  \n#>  3rd Qu.:0.04731   3rd Qu.:0.14265   3rd Qu.:0.2819  \n#>  Max.   :0.06353   Max.   :0.17648   Max.   :0.3037  \n#>        l               lum        \n#>  Min.   :0.2092   Min.   :0.1513  \n#>  1st Qu.:0.2232   1st Qu.:0.1966  \n#>  Median :0.2759   Median :0.2247  \n#>  Mean   :0.3076   Mean   :0.2241  \n#>  3rd Qu.:0.3815   3rd Qu.:0.2661  \n#>  Max.   :0.4625   Max.   :0.2766\noldpar <- par(no.readonly = TRUE)\npar(mfrow = c(2, 6), oma = c(3, 3, 0, 0))\nlayout(rbind(\n  c(2, 1, 4, 3, 6, 5),\n  c(1, 1, 3, 3, 5, 5),\n  c(8, 7, 10, 9, 12, 11),\n  c(7, 7, 9, 9, 11, 11)\n))\n\nsppspecol <- spec2rgb(sppspec)\n\nfor (i in 1:6) {\n  par(mar = c(2, 2, 2, 2))\n  plot(sppspec,\n    select = i + 1,\n    col = sppspecol,\n    lwd = 3,\n    ylim = c(0, 100)\n  )\n  par(mar = c(4.1, 2.5, 2.5, 2))\n  barplot(as.matrix(vismod1[i, 1:4]),\n    yaxt = \"n\",\n    col = \"black\"\n  )\n}\n\nmtext(\"Wavelength (nm)\", side = 1, outer = TRUE, line = 1)\nmtext(\"Reflectance (%)\", side = 2, outer = TRUE, line = 1)\npar(oldpar)\nideal_dichromat <- sensmodel(c(350, 650))\nplot(ideal_dichromat, ylab = \"Absorbance\")\nvismod.idi <- vismodel(sppspec,\n  visual = ideal_dichromat,\n  relative = FALSE\n)\nvismod.idi#>             lmax350   lmax650 lum\n#> cardinal 0.14578161 0.3519237  NA\n#> jacana   0.09155090 0.3179246  NA\n#> oriole   0.06981615 0.3775647  NA\n#> parakeet 0.10579320 0.1727374  NA\n#> robin    0.04727061 0.2174901  NA\n#> tanager  0.16438304 0.2148739  NA"},{"path":"analysing-data.html","id":"the-receptor-noise-model","chapter":"3 Analysing Data","heading":"3.1.4.5 The Receptor Noise Model","text":"receptor-noise limited (RNL) model Vorobyev et al. (1998), Vorobyev et al. (2001) offers basis estimating ‘perceptual’ distance coloured stimuli (depending available physiological behavioural data), assumes simultaneous discrimination colours fundamentally limited photoreceptor noise. Colour distances RNL model can calculated using inverse noise--signal ratio, known Weber fraction (\\(w_i\\) cone \\(\\)). Weber fraction can calculated noise--signal ratio cone \\(\\) (\\(v_i\\)) relative number receptor cells type \\(\\) within receptor field (\\(n_i\\)):\\[w_i = \\frac{v_i}{\\sqrt{n_i}}\\]\\(w_i\\) value used noise considering neural noise mechanisms. Alternatively, model can consider intensity colour signal contributes noise (photoreceptor, quantum, noise). case, noise receptor \\(\\) calculated :\\[w_i = \\sqrt{\\frac{v_i^2}{\\sqrt{n_i}} + \\frac{2}{Q_a+Q_b}}\\]\\(\\) \\(b\\) refer two colour signals compared. Note values \\(Q_a\\) \\(Q_b\\) high, second portion equation tends zero, formulas yield similar results. Hence, important quantum catch calculated appropriate illuminant scale, described .Colour distances obtained weighting Euclidean distance photoreceptor quantum catches Weber fraction cones (\\(\\Delta S\\)). units measures noise-weighted Euclidean distances measurements, often referred \\(\\Delta S\\) chromatic distances, \\(\\Delta L\\) achromatic, luminance, distances. relevant calculations :dichromats:\n\\[\\Delta S = \\sqrt{\\frac{(\\Delta f_1 - \\Delta f_2)^2}{w_1^2+w_2^2}}\\]trichromats:\n\\[\\Delta S = \\sqrt{\\frac{w_1^2(\\Delta f_3 - \\Delta f_2)^2 + w_2^2(\\Delta f_3 - \\Delta f_1)^2 +\nw_3^2(\\Delta f_1 - \\Delta f_2)^2 }{ (w_1w_2)^2 + (w_1w_3)^2 + (w_2w_3)^2 }}\\]tetrachromats:\n\\[\\Delta S =\n\\sqrt{(w_1w_2)^2(\\Delta f_4 - \\Delta f_3)^2 + (w_1w_3)^2(\\Delta f_4 - \\Delta f_2)^2 +\n(w_1w_4)^2(\\Delta f_3 - \\Delta f_2)^2 + \\\\ (w_2w_3)^2(\\Delta f_4 - \\Delta f_1)^2 +\n(w_2w_4)^2(\\Delta f_3 - \\Delta f_1)^2 + (w_3w_4)^2(\\Delta f_2 - \\Delta f_1)^2 / \\\\\n((w_1w_2w_3)^2 + (w_1w_2w_4)^2 + (w_1w_3w_4)^2 + (w_2w_3w_4)^2)}\\]chromatic contrast. achromatic contrast (\\(\\Delta L\\)) can calculated based double cone receptor (combination receptors) responsible chromatic processing equation:\\[\\Delta L = \\frac{\\Delta f}{w}\\]","code":""},{"path":"analysing-data.html","id":"a-brief-note-on-terminology-and-just-noticeable-differences-jnds","chapter":"3 Analysing Data","heading":"3.1.4.5.1 A Brief Note on Terminology and ‘Just Noticeable Differences’ (JNDs)","text":"receptor-noise limited model often closely associated concept ‘just noticeable differences’ (JNDs), point JNDs presented unit distance measurement stimuli model/space. JND unique receptor-noise limited model, however, accurately described unit measurement. JND simply contrast threshold correlates discrimination criteria, 80% correct choices simultaneous-discrimination test, empirical work continues show correlation often species-, sex-, individual-, condition-, /stimulus-specific. therefore supportive move literature toward divorcing concept JND’s receptor-noise model specifically prefer accurate description distances receptor-noise space ‘noise-weighted Euclidean distances’, abbreviated \\(\\Delta S\\) (chromatic distances) \\(\\Delta L\\) (achromatic distances). Specific noise-weighted Euclidean distances \\(\\Delta S = 1\\) indeed correlate threshold discrimination, ‘just-noticeable difference’. circumstances holds (species, sex, viewing conditions, region colourspace stimulus occupies etc.) require behavioural validation, however, empirically estimated threshold given set circumstances unlikely hold firm face gross variation conditions.","code":""},{"path":"analysing-data.html","id":"noise-weighted-distances-with-coldist-and-bootcoldist","chapter":"3 Analysing Data","heading":"3.1.4.5.2 Noise-weighted Distances with coldist() and bootcoldist()","text":"pavo implements noise-weighted colour distance calculations functions coldist() bootcoldist(), assuming raw receptor quantum catches provided (via relative = FALSE vismodel()). achromatic contrast, coldist() uses n4 calculate \\(w\\) achromatic contrast. Note even \\(Q_i\\) chosen, values still log-transformed. option available case user wants specify data frame quantum catches generated vismodel() input. case, argument qcatch used inform function \\(Q_i\\) \\(f_i\\) values used (note input coldist() object generated using vismodel() function, argument ignored.) type noise calculated can selected coldist() argument noise (accepts either \"neural\" \"quantum\").dS chromatic contrast (\\(\\Delta S\\)) dL achromatic contrast (\\(\\Delta L\\)). Note , default, achromatic = FALSE, dL isn’t included second result (maintain consistency since, vismodel() function, achromatic argument defaults none). expected, values really high avian colour vision, since colours species quite different enhanced discriminatory ability four compared two cones.coldist() also subset argument, useful certain comparisons interest (example, colour patches background, comparisons among species body patch). subset can vector length one two. one subsetting option passed, comparisons matching argument returned (useful case comparing background, example). two values passed, comparisons made samples match rule (partial string matching regular expressions accepted). example, compare::bootstrap-based variant coldist(), described Maia White (2018) part general analytical framework, implemented via function bootcoldist(). name suggests, bootcoldist() uses bootstrap procedure generate confidence intervals mean chromatic /achromatic distance two samples colours. benefit generating useful errors around distance estimates, may also inspected inclusion appropriate ‘threshold’, asking common kinds questions relate -group differences (e.g. animals-vs-backgrounds, sexual dichromatism, colour polymorphism). function’s arguments shared coldist() save extra requirements. one, argument used specify grouping variable defines groups compared, boot.n alpha control number bootstrap replicates confidence level confidence interval, respectively. latter two sensible defaults, argument required.run present quick example tests colour differences across three body regions (breast, crown, throat) finch Sicalis citrina, given seven measures region different males.plot results good measure. can see pairwise comparisons chest, breast, throat quite chromatically distinct, breast throat much similar colour, perhaps point indistinguishable.\nFigure 3.5: bootstrapped colour distances throat, chest, breast regions male Sicalis citrina.\n","code":"\ncoldist(vismod1,\n  noise = \"neural\", achromatic = TRUE, n = c(1, 2, 2, 4),\n  weber = 0.1, weber.achro = 0.1\n)#>      patch1   patch2        dS        dL\n#> 1  cardinal   jacana  8.436191 3.6082787\n#> 2  cardinal   oriole  7.874540 3.5245174\n#> 3  cardinal parakeet  8.010167 0.7553289\n#> 4  cardinal    robin  5.865464 2.4275512\n#> 5  cardinal  tanager 10.116173 2.2442493\n#> 6    jacana   oriole 10.114671 0.0837613\n#> 7    jacana parakeet  4.316712 2.8529498\n#> 8    jacana    robin  3.499380 6.0358299\n#> 9    jacana  tanager  5.064380 1.3640294\n#> 10   oriole parakeet  8.147778 2.7691885\n#> 11   oriole    robin  7.200079 5.9520686\n#> 12   oriole  tanager 13.532690 1.2802681\n#> 13 parakeet    robin  4.744364 3.1828801\n#> 14 parakeet  tanager  5.886396 1.4889204\n#> 15    robin  tanager  7.679779 4.6718005\ncoldist(vismod.idi, n = c(1, 2), weber = 0.1)#>      patch1   patch2        dS dL\n#> 1  cardinal   jacana 2.0993283 NA\n#> 2  cardinal   oriole 4.6567462 NA\n#> 3  cardinal parakeet 2.2575457 NA\n#> 4  cardinal    robin 3.7236780 NA\n#> 5  cardinal  tanager 3.5417700 NA\n#> 6    jacana   oriole 2.5574178 NA\n#> 7    jacana parakeet 4.3568740 NA\n#> 8    jacana    robin 1.6243496 NA\n#> 9    jacana  tanager 5.6410983 NA\n#> 10   oriole parakeet 6.9142918 NA\n#> 11   oriole    robin 0.9330682 NA\n#> 12   oriole  tanager 8.1985162 NA\n#> 13 parakeet    robin 5.9812236 NA\n#> 14 parakeet  tanager 1.2842244 NA\n#> 15    robin  tanager 7.2654480 NA\ncoldist(vismod1, subset = \"cardinal\")#>     patch1   patch2        dS dL\n#> 1 cardinal   jacana  8.436191 NA\n#> 2 cardinal   oriole  7.874540 NA\n#> 3 cardinal parakeet  8.010167 NA\n#> 4 cardinal    robin  5.865464 NA\n#> 5 cardinal  tanager 10.116173 NA\ncoldist(vismod1, subset = c(\"cardinal\", \"jacana\"))#>     patch1 patch2       dS dL\n#> 1 cardinal jacana 8.436191 NA\n# Load the data\ndata(sicalis)\n\n# Construct a model using an avian viewer\nsicmod <- vismodel(sicalis, visual = \"avg.uv\", relative = FALSE)\n\n# Create a grouping variable to group by body region,\n# informed by the spectral data names\nregions <- substr(rownames(sicmod), 6, 6)\n\n# Estimate bootstrapped colour-distances\nsicdist <- bootcoldist(sicmod,\n  by = regions,\n  n = c(1, 2, 2, 4),\n  weber = 0.05\n)\n\n# Take a look at the resulting pairwise estimates\nsicdist#>       dS.mean    dS.lwr    dS.upr\n#> B-C  9.253097 5.7015179 14.013095\n#> B-T  3.483528 0.3728945  9.509223\n#> C-T 12.221038 8.1736179 16.899949\nplot(sicdist[, 1],\n  ylim = c(0, 20),\n  pch = 21,\n  bg = 1,\n  cex = 2,\n  xaxt = \"n\",\n  xlab = \"Centroid comparison\",\n  ylab = \"Chromatic contrast (dS)\"\n)\naxis(1, at = 1:3, labels = rownames(sicdist))\nsegments(1:3, sicdist[, 2], 1:3, sicdist[, 3], lwd = 2) # Add CI's\nabline(h = 1, lty = 3, lwd = 2) # Add a 'threshold' line at dS = 1"},{"path":"analysing-data.html","id":"converting-receptor-noise-corrected-distances-to-cartesian-coordinates","chapter":"3 Analysing Data","heading":"3.1.4.5.3 Converting receptor noise-corrected distances to Cartesian coordinates","text":"can convert noise-corrected Euclidean distances coordinates Cartesian ‘noise-corrected space’ function jnd2xyz(). space, distance points corresponds exactly noise-corrected Euclidean distance estimated receptor-noise limited model. Note absolute position points XYZ space arbitrary, however, therefore function allows rotate data , example, vector leading long-wavelength cone aligns X axis:can plot well:\nFigure 3.6: Spectral data receptor noise-corrected colourspace\naxes colourspace denote noise-corrected Euclidean distances. information functions, see ?jnd2xyz, ?jndrot ?jndplot.","code":"\nfakedata1 <- vapply(\n  seq(100, 500, by = 20),\n  function(x) {\n    rowSums(cbind(\n      dnorm(300:700, x, 30),\n      dnorm(300:700, x + 400, 30)\n    ))\n  },\n  numeric(401)\n)\n\n# Creating idealized specs with varying saturation\nfakedata2 <- vapply(\n  c(500, 300, 150, 105, 75, 55, 40, 30),\n  function(x) dnorm(300:700, 550, x),\n  numeric(401)\n)\n\nfakedata1 <- as.rspec(data.frame(wl = 300:700, fakedata1))\nfakedata1 <- procspec(fakedata1, \"max\")\nfakedata2 <- as.rspec(data.frame(wl = 300:700, fakedata2))\nfakedata2 <- procspec(fakedata2, \"sum\")\nfakedata2 <- procspec(fakedata2, \"min\")\n\n# Converting reflectance to percentage\nfakedata1[, -1] <- fakedata1[, -1] * 100\nfakedata2[, -1] <- fakedata2[, -1] / max(fakedata2[, -1]) * 100\n\n# Combining and converting to rspec\nfakedata.c <- data.frame(\n  wl = 300:700,\n  fakedata1[, -1],\n  fakedata2[, -1]\n)\nfakedata.c <- as.rspec(fakedata.c)\n# Visual model and colour distances\nfakedata.vm <- vismodel(fakedata.c,\n  relative = FALSE,\n  achromatic = \"all\"\n)\nfakedata.cd <- coldist(fakedata.vm,\n  noise = \"neural\", n = c(1, 2, 2, 4),\n  weber = 0.1, achromatic = TRUE\n)\n\n# Converting to Cartesian coordinates\nfakedata.cc <- jnd2xyz(fakedata.cd,\n  ref1 = \"l\",\n  axis1 = c(1, 0, 0),\n  ref2 = NULL\n)\nhead(fakedata.cc)#>             x          y         z      lum\n#> X1 -26.165302   3.692783 -17.71718 1.430788\n#> X2 -11.212399  -2.085407 -27.97937 2.315951\n#> X3   3.076291  -7.441594 -37.76761 3.621349\n#> X4  16.523287 -12.475488 -46.33606 4.341465\n#> X5  25.812150 -17.848152 -40.71621 4.444027\n#> X6  31.912643 -23.368560 -24.79660 4.046863\nplot(fakedata.cc,\n  theta = 55,\n  phi = 25,\n  col = spec2rgb(fakedata.c)\n)"},{"path":"analysing-data.html","id":"colourspaces","chapter":"3 Analysing Data","heading":"3.1.4.6 Colourspaces","text":"Another general, flexible way represent stimuli via colourspace model. models photon catches expressed relative values (quantum catches receptors involved chromatic discrimination sum 1). maximum stimulation cone \\(n\\) placed vertex \\((n-1)\\)-dimensional polygon encompasses theoretical colours can perceived visual system. avian visual system comprised four cones, example, colours can placed somewhere volume tetrahedron, four vertices represents maximum stimulation particular cone type.Though models account receptor noise (thus allow estimate noise-weighted distances), presents several advantages. First, make intuitive representation colour points accounting attributes colour vision signal receiver. Second, allow calculation several interesting variables represent colour. example, hue can estimated angle point relative xy plane (blue-green-red) z axis (UV); saturation can estimated distance point achromatic centre.data(flowers) new example dataset consisting reflectance spectra 36 Australian angiosperm species, ’ll use illustrate following colourspace modelling.","code":"\ndata(flowers)\n\nhead(flowers[1:4])#>    wl Goodenia_heterophylla Goodenia_geniculata Goodenia_gracilis\n#> 1 300             1.7426387            1.918962         0.3638354\n#> 2 301             1.5724849            1.872966         0.3501921\n#> 3 302             1.4099808            1.828019         0.3366520\n#> 4 303             1.2547709            1.784152         0.3231911\n#> 5 304             1.1064997            1.741398         0.3097854\n#> 6 305             0.9648117            1.699792         0.2964107"},{"path":"analysing-data.html","id":"di--tri--and-tetrachromatic-colourspaces","chapter":"3 Analysing Data","heading":"3.1.4.6.1 Di-, Tri-, and Tetrachromatic Colourspaces","text":"pavo extensive modelling visualisation capabilities generic di-, tri-, tetra-chromatic spaces, uniting approaches cohesive workflow. colourspace models, first estimate relative quantum catches various assumptions using vismodel() function, converting set values location colourspace using space argument colspace() (function can also set try detect dimensionality colourspace automatically). di- tri- tetrachromatic spaces, colspace() calculates coordinates stimuli :Dichromats:\n\\[x = \\frac{1}{\\sqrt{2}}(Q_l - Q_s)\\]Trichromats:\\[\n\\begin{split}\nx &= \\frac{1}{\\sqrt{2}}(Q_l - Q_m) \\\\\ny &= \\frac{\\sqrt{2}}{\\sqrt{3}}(Q_s - \\frac{Q_l + Q_m}{2})\n\\end{split}\n\\]\nTetrachromats:\\[\n\\begin{split}\nx &= \\frac{1}{\\sqrt{2}}(Q_l - Q_m) \\\\\ny &= \\frac{\\sqrt{2}}{\\sqrt{3}}(Q_s - \\frac{Q_l + Q_m}{2})\nz &= \\frac{\\sqrt{3}}{2}(Q_u - \\frac{Q_l + Q_m + Q_s}{3})\n\\end{split}\n\\]\\(Q_u\\), \\(Q_s\\), \\(Q_m\\), \\(Q_l\\) refer quantum catch estimates UV-, short, medium-, long-wavelength photoreceptors, respectively.dichromatic example, can model floral reflectance data using visual system domestic dog Canis familiaris, two cones maximal sensitivity near 440 560 nm.output contains values relative stimulation short- long-wavelength sensitive photoreceptors associated flower, along single coordinate dichromatic space r.vector (distance origin). visualise points lie, can simply plot segment.\nFigure 3.7: Flowers dichromatic colourspace, modelled according canid visual system.\ntrichromatic viewer can use honeybee Apis mellifera, one significant widespread pollinators. ’ll also transform quantum catches according Fechner’s law specifying qcatch = 'fi', model photoreceptor stimulation bright conditions scaling illuminant scale argument.case dichromat, output contains relative photoreceptor stimulations, coordinates Maxwell triangle, well ‘hue angle’ h.theta distance origin (r.vec).\nFigure 3.8: Floral reflectance Maxwell triangle, considering honeybee visual system.\nFinally, ’ll draw blue tit’s visual system model floral reflectance spectra tetrahedral space, using log-transformed quantum catches assuming bright viewing conditions.Tetrahedral data (via colspace(space = 'tcs')) may plotted standard static tetrahedron using plot(), can visualised part interactive tetrahedron using tcsplot() accessory functions tcspoints() tcsvol() adding points convex hulls, respectively. colourspace plots number associated graphical options, though theta phi arguments particularly useful case, control orientation (degrees) tetrahedron xy yz planes, respectively.plotting tetrahedral colourspace, one can also force perspective changing size points relative distance plane observation, using arguments perspective = TRUE controlling size range range argument. Several options control appearance plot, can check using ?plot.colspace ?tetraplot\nFigure 3.9: Flowers tetrahedral colourspace modelled using visual phenotype blue tit. Point size used force perspective\nTwo additional functions may help tetrahedral colourspace plotting:axistetra() function can used draw arrows showing direction magnitude distortion x, y z tetrahedral plot.legendtetra() allows add legend plot.\nFigure 3.10: Flowers tetrahedral colourspace, varied orientations perspectives, modelled using visual phenotype blue tit.\ntetrahedral models, another plotting option available projplot, projects colour points surface sphere encompassing tetrahedron. plot particularly useful see differences hue.\nFigure 3.11: Projection plot tetrahedral colour space.\nEstimating colour volumesA useful function tri- tetrahedral models voloverlap(), calculates overlap tri- tetrahedral colour volume two sets points. can useful explore whether different species occupy similar (overlapping) different (non- overlapping) “sensory niches”, test mimetism, dichromatism, etc. (Stoddard Stevens 2011). demonstrate, use sicalis dataset, includes measurements crown (C), throat (T) breast (B) seven stripe-tailed yellow finches (Sicalis citrina).use dataset test overlap volume determined measurements body parts multiple individuals tetrahedral colourspace (note option plot plotting volumes):function voloverlap() gives volume (\\(V\\)) convex hull delimited overlap two original volumes, two proportions calculated : \\[\\text{vsmallest} = V_{overlap} / \\min(V_A, V_B)\\] \\[\\text{vboth} = V_{overlap} / (V_A + V_B)\\]. Thus, one volumes entirely contained , vsmallest equal 1. can clearly see overlap throat breast colours (6%), throat crown colours (Figures ).Alternatively, \\(\\alpha\\)-shapes new tool available pavo estimate colour volumes,\nallowing presence voids pockets. \\(\\alpha\\)-shapes may thus lead \naccurate measurement “colourfulness” convex hulls. information\ntheoretical background, please report related article (Gruson 2020).can plot colour volume using \\(\\alpha\\)-shape vol() function\n(non-interactive plots, tcsvol() otherwise) specifying\ntype = \"alpha\". default, use \\(\\alpha^*\\) value defined \nGruson (2020).Alternatively, can set \\(\\alpha\\) parameter value choice via avalue\nargument:previous examples, focused \\(\\alpha\\)-shapes chromaticity diagrams since\ncommon space convex hulls (\\(\\alpha\\)-shapes aim \nreplacing) used. also possible use \\(\\alpha\\)-shapes spaces,\nperceptually uniform (noise-corrected) spaces.Let’s first build uniform space look data points space:High-level functions build \\(\\alpha\\)-shape directly pavo yet\nimplemented can use alphashape3d package directly compute\n\\(\\alpha\\)-shapes, volume display 3D interactive plot.\\(\\alpha\\)-shapes can also used measure colour similarity two objects,\ncomputing colour volume overlap. done type = \"alpha\" argument\nvoloverlap(). example, let’s compare ibce agaub colour volume \ncrown breast stripe-tailed yellow finches (Sicalis citrina),\ntime \\(\\alpha\\)-shapes:Summary variables groups pointsAnother advantage colourspace models allow calculation useful summary statistics groups points, centroid points, total volume occupied (), mean variance hue span mean saturation. pavo, result colspace() call object class colspace, thus summary statistics can calculated simply calling summary. Note summary call can also take vector group identities, variables calculated group separately:important highlight oftentimes, properties visual system /illuminant make impossible reach entirety given colourspace. can view maximum gamut given viewer switching gamut argument TRUE plot.colspace():information also available summary, “Max possible chromatic volume” line:","code":"\nvis.flowers <- vismodel(flowers, visual = \"canis\")\n\ndi.flowers <- colspace(vis.flowers, space = \"di\")\n\nhead(di.flowers)#>                                s         l           x      r.vec\n#> Goodenia_heterophylla 0.52954393 0.4704561 -0.04178143 0.04178143\n#> Goodenia_geniculata   0.25430150 0.7456985  0.34747015 0.34747015\n#> Goodenia_gracilis     0.01747832 0.9825217  0.68238870 0.68238870\n#> Xyris_operculata      0.39433933 0.6056607  0.14942675 0.14942675\n#> Eucalyptus_sp         0.40628552 0.5937145  0.13253229 0.13253229\n#> Faradaya_splendida    0.23166580 0.7683342  0.37948187 0.37948187\n#>                       lum\n#> Goodenia_heterophylla  NA\n#> Goodenia_geniculata    NA\n#> Goodenia_gracilis      NA\n#> Xyris_operculata       NA\n#> Eucalyptus_sp          NA\n#> Faradaya_splendida     NA\nplot(di.flowers, col = spec2rgb(flowers))\nvis.flowers <- vismodel(flowers,\n  visual = \"apis\",\n  qcatch = \"fi\",\n  scale = 10000\n)\n\ntri.flowers <- colspace(vis.flowers, space = \"tri\")\n\nhead(tri.flowers)#>                               s         m         l            x\n#> Goodenia_heterophylla 0.2882383 0.3587254 0.3530363 -0.004022828\n#> Goodenia_geniculata   0.2475326 0.3549832 0.3974842  0.030052720\n#> Goodenia_gracilis     0.1373117 0.3125304 0.5501579  0.168028001\n#> Xyris_operculata      0.2395035 0.3729820 0.3875145  0.010275990\n#> Eucalyptus_sp         0.2760091 0.3548096 0.3691813  0.010162377\n#> Faradaya_splendida    0.2654951 0.3431266 0.3913783  0.034119147\n#>                                 y    h.theta      r.vec lum\n#> Goodenia_heterophylla -0.05522995 -1.6435057 0.05537626  NA\n#> Goodenia_geniculata   -0.10508396 -1.2922439 0.10929687  NA\n#> Goodenia_gracilis     -0.24007647 -0.9601417 0.29303604  NA\n#> Xyris_operculata      -0.11491764 -1.4816131 0.11537616  NA\n#> Eucalyptus_sp         -0.07020755 -1.4270471 0.07093922  NA\n#> Faradaya_splendida    -0.08308452 -1.1811377 0.08981733  NA\nplot(tri.flowers, pch = 21, bg = spec2rgb(flowers))\nvis.flowers <- vismodel(flowers,\n  visual = \"bluetit\",\n  qcatch = \"fi\",\n  scale = 10000\n)\n\ntetra.flowers <- colspace(vis.flowers, space = \"tcs\")\n\nhead(tetra.flowers)#>                               u         s         m         l\n#> Goodenia_heterophylla 0.2274310 0.2659669 0.2524170 0.2541851\n#> Goodenia_geniculata   0.1625182 0.2721621 0.2828016 0.2825182\n#> Goodenia_gracilis     0.0428552 0.2443091 0.3504414 0.3623943\n#> Xyris_operculata      0.1766234 0.2709785 0.2642637 0.2881344\n#> Eucalyptus_sp         0.2118481 0.2609468 0.2637023 0.2635028\n#> Faradaya_splendida    0.1844183 0.2557660 0.2786393 0.2811764\n#>                               u.r          s.r         m.r\n#> Goodenia_heterophylla -0.02256897  0.015966893 0.002417012\n#> Goodenia_geniculata   -0.08748184  0.022162064 0.032801599\n#> Goodenia_gracilis     -0.20714480 -0.005690920 0.100441373\n#> Xyris_operculata      -0.07337659  0.020978454 0.014263689\n#> Eucalyptus_sp         -0.03815190  0.010946788 0.013702317\n#> Faradaya_splendida    -0.06558169  0.005765955 0.028639328\n#>                               l.r            x            y\n#> Goodenia_heterophylla 0.004185066 -0.007214866 -0.005415708\n#> Goodenia_geniculata   0.032518179  0.006341799  0.003861848\n#> Goodenia_gracilis     0.112394348  0.072312163  0.033297418\n#> Xyris_operculata      0.038134446  0.010505857 -0.010813615\n#> Eucalyptus_sp         0.013502794  0.001565228  0.001044768\n#> Faradaya_splendida    0.031176408  0.015560661  0.007189965\n#>                                 z    h.theta     h.phi      r.vec\n#> Goodenia_heterophylla -0.02256897 -2.4976873 -1.190529 0.02430520\n#> Goodenia_geniculata   -0.08748184  0.5469755 -1.486123 0.08779638\n#> Goodenia_gracilis     -0.20714480  0.4315247 -1.203879 0.22191605\n#> Xyris_operculata      -0.07337659 -0.7998327 -1.368146 0.07490949\n#> Eucalyptus_sp         -0.03815190  0.5885699 -1.521510 0.03819828\n#> Faradaya_splendida    -0.06558169  0.4328380 -1.315140 0.06778487\n#>                           r.max r.achieved lum\n#> Goodenia_heterophylla 0.2692325 0.09027589  NA\n#> Goodenia_geniculata   0.2508989 0.34992737  NA\n#> Goodenia_gracilis     0.2678272 0.82857920  NA\n#> Xyris_operculata      0.2552227 0.29350636  NA\n#> Eucalyptus_sp         0.2503039 0.15260760  NA\n#> Faradaya_splendida    0.2583986 0.26232676  NA\nplot(tetra.flowers,\n  pch = 21,\n  bg = spec2rgb(flowers),\n  perspective = TRUE,\n  range = c(1, 2),\n  cex = 0.5\n)\nplot(tetra.flowers,\n  pch = 21,\n  bg = spec2rgb(flowers)\n)\naxistetra(x = 0, y = 1.8)\nplot(tetra.flowers,\n  theta = 110,\n  phi = 10,\n  pch = 21,\n  bg = spec2rgb(flowers)\n)\naxistetra(x = 0, y = 1.8)\nprojplot(tetra.flowers, pch = 20, col = spec2rgb(flowers))\ndata(sicalis)\ntcs.sicalis.C <- subset(colspace(vismodel(sicalis)), \"C\")\ntcs.sicalis.T <- subset(colspace(vismodel(sicalis)), \"T\")\ntcs.sicalis.B <- subset(colspace(vismodel(sicalis)), \"B\")\nvoloverlap(tcs.sicalis.T, tcs.sicalis.B, plot = TRUE)#>           vol1         vol2   overlapvol vsmallest      vboth\n#> 1 5.183721e-06 6.281511e-06 6.904074e-07 0.1331876 0.06407598\nvoloverlap(tcs.sicalis.T, tcs.sicalis.C, plot = TRUE)#>           vol1         vol2 overlapvol vsmallest vboth\n#> 1 5.183721e-06 4.739152e-06          0         0     0\ndata(flowers)\nvis_flowers <- vismodel(flowers, visual = \"avg.uv\")\ntcs_flowers <- colspace(vis_flowers)\nplot(tcs_flowers)\nvol(tcs_flowers, type = \"alpha\")#> Warning in rgl.init(initValue, onlyNULL): RGL: unable to open X11\n#> display#> Warning: 'rgl.init' failed, running with 'rgl.useNULL = TRUE'.#> 'avalue' automatically set to 1.8275e-01\nplot(tcs_flowers)\nvol(tcs_flowers, type = \"alpha\", avalue = 0.5)\ncd_flowers <- coldist(vis_flowers)#> Quantum catch are relative, distances may not be meaningful#> Calculating noise-weighted Euclidean distances\nxy_flowers <- jnd2xyz(cd_flowers)\nplot(xy_flowers)\nlibrary(alphashape3d)#> Loading required package: geometry#> Loading required package: rgl\nashape_jnd <- ashape3d(as.matrix(xy_flowers), alpha = 10)\nvolume_ashape3d(ashape_jnd)#> [1] 748.863\nplot(ashape_jnd)#> Device  1  : alpha =  10\ndata(sicalis)\ntcs.sicalis.C <- subset(colspace(vismodel(sicalis)), \"C\")\ntcs.sicalis.B <- subset(colspace(vismodel(sicalis)), \"B\")\nvoloverlap(tcs.sicalis.C,\n  tcs.sicalis.B,\n  type = \"alpha\",\n  plot = TRUE\n)#> 'avalue' automatically set to 2.4445e-02#> 'avalue' automatically set to 2.6255e-01#> Warning: interactive = FALSE has not been implemented yet,\n#> falling back tointeractive plot.#>           vol1         vol2 s_in1 s_in2 s_inboth s_ineither\n#> 1 1.849436e-06 4.586381e-06     2     4        0          6\n#>   psmallest pboth\n#> 1         0     0\nsummary(tetra.flowers)#> Colorspace & visual model options:\n#>  * Colorspace: tcs \n#>  * Quantal catch: fi \n#>  * Visual system, chromatic: bluetit \n#>  * Visual system, achromatic: none \n#>  * Illuminant: ideal, scale = 10000 (von Kries colour correction not applied) \n#>  * Background: ideal \n#>  * Relative: TRUE \n#>  * Max possible chromatic volume: NA#> 'avalue' automatically set to 1.9861e-01#>            centroid.u centroid.s centroid.m centroid.l        c.vol\n#> all.points  0.1948478  0.2554421  0.2704411   0.279269 0.0002510915\n#>              rel.c.vol  colspan.m   colspan.v huedisp.m huedisp.v\n#> all.points 0.001159742 0.05706825 0.001682224 0.6413439 0.3157949\n#>              mean.ra    max.ra        a.vol\n#> all.points 0.2428508 0.8285792 0.0001723672\nvis.flowers <- vismodel(flowers, visual = \"ctenophorus\")\ntri.flowers <- colspace(vis.flowers)\nplot(tri.flowers, pch = 21, bg = spec2rgb(flowers), gamut = TRUE)\nsummary(tri.flowers)#> Colorspace & visual model options:\n#>  * Colorspace: trispace \n#>  * Quantal catch: Qi \n#>  * Visual system, chromatic: ctenophorus \n#>  * Visual system, achromatic: none \n#>  * Illuminant: ideal, scale = 1 (von Kries colour correction not applied) \n#>  * Background: ideal \n#>  * Relative: TRUE \n#>  * Max possible chromatic volume: 0.4729301#>        s                 m                l         \n#>  Min.   :0.02084   Min.   :0.2318   Min.   :0.2066  \n#>  1st Qu.:0.18617   1st Qu.:0.3005   1st Qu.:0.3806  \n#>  Median :0.23206   Median :0.3452   Median :0.4180  \n#>  Mean   :0.23206   Mean   :0.3225   Mean   :0.4454  \n#>  3rd Qu.:0.29330   3rd Qu.:0.3513   3rd Qu.:0.5039  \n#>  Max.   :0.44720   Max.   :0.3660   Max.   :0.7474  \n#>        x                  y               h.theta       \n#>  Min.   :-0.09877   Min.   :-0.38273   Min.   :-1.9491  \n#>  1st Qu.: 0.02242   1st Qu.:-0.18023   1st Qu.:-1.2269  \n#>  Median : 0.05899   Median :-0.12404   Median :-0.9590  \n#>  Mean   : 0.08689   Mean   :-0.12404   Mean   :-0.5767  \n#>  3rd Qu.: 0.12564   3rd Qu.:-0.04903   3rd Qu.:-0.7747  \n#>  Max.   : 0.36460   Max.   : 0.13946   Max.   : 2.6273  \n#>      r.vec           lum         \n#>  Min.   :0.02264   Mode:logical  \n#>  1st Qu.:0.08330   NA's:36       \n#>  Median :0.13917                 \n#>  Mean   :0.17858                 \n#>  3rd Qu.:0.24002                 \n#>  Max.   :0.52860"},{"path":"analysing-data.html","id":"the-colour-hexagon","chapter":"3 Analysing Data","heading":"3.1.4.6.2 The Colour Hexagon","text":"hexagon colour space Chittka (1992) generalised colour-opponent model hymenopteran vision found extremely broad use, particularly studies bee-flower interactions. ’s also often broadly applied across hymenopteran species, photopigments underlying trichromatic vision Hymenoptera appear quite conserved (Briscoe Chittka 2001). ’s particularly useful colour distances within hexagon extensively validated behaviour, least among honeybees, thus offer relatively reliable measure perceptual distance.hexagon, photoreceptor quantum catches typically hyperbolically transformed (pavo return warning transform selected), vonkries correction often used used model photoreceptor adaptation vegetation background. can now specified vismodel(). including optional use built-‘green’ vegetation background. Note although colourspace model, specific relative = FALSE return unnormalised quantum catches, required model.can apply hexagon model colspace, convert photoreceptor excitation values coordinates hexagon according :\\[\n\\begin{split}\nx &= \\frac{\\sqrt{3}}{2(E_g + E_{uv})}\\\\\ny &= E_b - 0.5(E_{uv} + E_g)\n\\end{split}\n\\], output includes photoreceptor excitation values short- medium- long-wave sensitive photoreceptors, x y coordinates, measures hue saturation stimulus. hexagon model also outputs two additional measures subjective ‘bee-hue’; sec.fine sec.coarse. sec.fine describes location stimuli within one 36 ‘hue sectors’ specified radially dissecting hexagon 10-degree increments. sec.coarse follows similar principle, though hexagon divided five ‘bee-hue’ sectors: UV, UV-blue, blue, blue-green, green, UV-green. can easily visualised specifying sectors = 'coarse sectors = 'fine' call plot modelling.\nFigure 3.12: Flowers modelled hymenopteran colour hexagon Chittka (1992), overlain coarse bee-hue sectors.\nNote ‘green receptor contrast’ (per Spaethe (2001) much subsequent work) hexagon model often interest, given role mediating detection stimuli small visual angles. (necessity) value returned lum output vismodel(). Instead, ‘green contrast’ simply long-wavelength receptor excitation values returned (l), long wavelength receptor specified ‘achromatic’ receptor vonkries transform applied (). literature, green contrast may expressed absolute excitation value ranging 0-1, 0.5 representing unity (.e. contrast), relative deviation 0.5.","code":"\nvis.flowers <- vismodel(flowers,\n  visual = \"apis\",\n  qcatch = \"Ei\",\n  relative = FALSE,\n  vonkries = TRUE,\n  achromatic = \"l\",\n  bkg = \"green\"\n)\nhex.flowers <- colspace(vis.flowers, space = \"hexagon\")\n\nhead(hex.flowers)#>                                s         m         l         x\n#> Goodenia_heterophylla 0.56572097 0.8237141 0.7053057 0.1208839\n#> Goodenia_geniculata   0.35761236 0.8176153 0.8670134 0.4411542\n#> Goodenia_gracilis     0.01888788 0.1622766 0.7810589 0.6600594\n#> Xyris_operculata      0.21080752 0.7345122 0.6796464 0.4060263\n#> Eucalyptus_sp         0.55622758 0.8515289 0.8208038 0.2291297\n#> Faradaya_splendida    0.45855056 0.7828905 0.8565895 0.3447118\n#>                                y   h.theta     r.vec sec.fine\n#> Goodenia_heterophylla  0.1882007  32.71320 0.2236793       30\n#> Goodenia_geniculata    0.2053024  65.04388 0.4865862       60\n#> Goodenia_gracilis     -0.2376968 109.80467 0.7015541      100\n#> Xyris_operculata       0.2892853  54.53092 0.4985412       50\n#> Eucalyptus_sp          0.1630132  54.57024 0.2812005       50\n#> Faradaya_splendida     0.1253205  70.02119 0.3667853       70\n#>                       sec.coarse       lum\n#> Goodenia_heterophylla  bluegreen 0.1680153\n#> Goodenia_geniculata    bluegreen 0.3548825\n#> Goodenia_gracilis          green 0.2313678\n#> Xyris_operculata       bluegreen 0.1518319\n#> Eucalyptus_sp          bluegreen 0.2787543\n#> Faradaya_splendida     bluegreen 0.3351008\nplot(hex.flowers,\n  sectors = \"coarse\",\n  pch = 21,\n  bg = spec2rgb(flowers)\n)"},{"path":"analysing-data.html","id":"the-colour-opponent-coding-coc-space","chapter":"3 Analysing Data","heading":"3.1.4.6.3 The Colour Opponent Coding (COC) Space","text":"colour opponent coding (coc) space earlier hymenopteran visual model (Backhaus 1991) , although now seldom used favour hexagon, may prove useful comparative work. initial estimation photoreceptor excitation similar hexagon, coc subsequently specifies B coordinates based empirically-derived weights output photoreceptor:\\[\n\\begin{split}\n&= -9.86E_u + 7.70E_b + 2.16E_g\\\\\nB &= -5.17E_u + 20.25E_b - 15.08E_g\n\\end{split}\n\\]\\(E_i\\) excitation value (hyperbolic-transformed quantum catch) photoreceptor \\(\\).B coordinates designated x y output coc consistency, model includes measure saturation r.vec, contains associated measure hue.\nFigure 3.13: Flowers colour-opponent-coding space Backhaus (1991), modelling according honeybee.\n","code":"\nvis.flowers <- vismodel(flowers,\n  visual = \"apis\",\n  qcatch = \"Ei\",\n  relative = FALSE,\n  vonkries = TRUE,\n  bkg = \"green\"\n)\n\ncoc.flowers <- colspace(vis.flowers, space = \"coc\")\n\nhead(coc.flowers)#>                                s         m         l        x\n#> Goodenia_heterophylla 0.56572097 0.8237141 0.7053057 2.288050\n#> Goodenia_geniculata   0.35761236 0.8176153 0.8670134 4.642329\n#> Goodenia_gracilis     0.01888788 0.1622766 0.7810589 2.750382\n#> Xyris_operculata      0.21080752 0.7345122 0.6796464 5.045218\n#> Eucalyptus_sp         0.55622758 0.8515289 0.8208038 2.845304\n#> Faradaya_splendida    0.45855056 0.7828905 0.8565895 3.357182\n#>                                y     r.vec lum\n#> Goodenia_heterophylla  3.1194224  5.407473  NA\n#> Goodenia_geniculata    1.6332926  6.275622  NA\n#> Goodenia_gracilis     -8.5899171 11.340299  NA\n#> Xyris_operculata       3.5349309  8.580149  NA\n#> Eucalyptus_sp          1.9900420  4.835346  NA\n#> Faradaya_splendida     0.5654568  3.922638  NA\nplot(coc.flowers,\n  pch = 21,\n  bg = spec2rgb(flowers),\n  yaxt = \"n\"\n)"},{"path":"analysing-data.html","id":"cie-spaces","chapter":"3 Analysing Data","heading":"3.1.4.6.4 CIE Spaces","text":"CIE (International Commission Illumination) colourspaces suite models human colour vision perception. pavo 1.0 now includes two commonly used: foundational 1931 CIE XYZ space, modern, perceptually calibrated CIE LAB space cylindrical CIE LCh transformation. Tristimulus values XYZ space calculated :\\[\n\\begin{split}\nX &= k\\int_{300}^{700}{R(\\lambda)(\\lambda)\\bar{x}(\\lambda)\\,d\\lambda}\\\\\nY &= k\\int_{300}^{700}{R(\\lambda)(\\lambda)\\bar{y}(\\lambda)\\,d\\lambda}\\\\\nZ &= k\\int_{300}^{700}{R(\\lambda)(\\lambda)\\bar{z}(\\lambda)\\,d\\lambda}\n\\end{split}\n\\]x, y, z trichromatic colour matching functions ‘standard colourimetric viewer’. functions designed describe average human’s chromatic response within specified viewing arc fovea (account uneven distribution cones across eye). pavo includes CIE 2-degree modern 10-degree standard observer, can selected visual option vismodel function. equations, k normalising factor\\[k = \\frac{100}{\\int_{300}^{700}{(\\lambda)\\bar{y}(\\lambda)\\,d\\lambda}}\\]chromaticity coordinates stimuli calculated \\[\n\\begin{split}\nx &= \\frac{X}{X + Y + Z}\\\\\ny &= \\frac{Y}{X + Y + Z}\\\\\nz &= \\frac{Z}{X + Y + Z} = 1 - x - y\n\\end{split}\n\\]modelling XYZ LAB spaces, ’ll use CIE 10-degree standard observer, assume D65 ‘standard daylight’ illuminant. , although colourspace models, need set relative = FALSE return raw quantum catch estimates, vonkries = TRUE account required normalising factor (), achromatic = 'none' since applicable way estimate luminance CIE models. models particular requirements, vismodel() output warnings /errors unusual non-standard arguments specified.output simply tristimulus values chromaticity coordinates stimuli, can visualise results (along line connecting monochromatic loci, default) calling\nFigure 3.14: Floral reflectance CIEXYZ human visual model. Note space perceptually calibrated, make inferences similarity differences colours based relative location.\nLab space recent development, colour-opponent model attempts mimic nonlinear responses human eye. Lab space also calibrated (unlike XYZ space) Euclidean distances points represent relative perceptual distances. means two stimuli farther apart Lab space perceived different two closer points. name suggests, dimensions Lab space Lightness (.e. subjective brightness), along two colour-opponent dimensions designated b. colspace() function, space = cielab, simply converts points XYZ model according :$$\\[\nf(x)=\\begin{cases}\nx^\\frac{1}{3} & \\text{} x > 0.008856 \\\\\n7.787x + \\frac{4}{29} & \\text{} x \\leq 0.008856\n\\end{cases}\n\\], \\(X_n, Y_n, Z_n\\) neutral point values model visual adaptation, calculated :\\[\n\\begin{split}\nX_n &= \\int_{300}^{700}{R_n(\\lambda)(\\lambda)\\bar{x}(\\lambda)\\,d\\lambda}\\\\\nY_n &= \\int_{300}^{700}{R_n(\\lambda)(\\lambda)\\bar{y}(\\lambda)\\,d\\lambda}\\\\\nZ_n &= \\int_{300}^{700}{R_n(\\lambda)(\\lambda)\\bar{z}(\\lambda)\\,d\\lambda}\n\\end{split}\n\\]\\(R_n(\\lambda)\\) perfect diffuse reflector (.e. 1).output now contains tristimulus XYZ values, well Lab counterparts, coordinates Lab space. can also visualised three-dimensional Lab space calling plot:\nFigure 3.15: Floral reflectance spectra represented CIELab model human colour sensation.\n","code":"\nvis.flowers <- vismodel(flowers,\n  visual = \"cie10\",\n  illum = \"D65\",\n  vonkries = TRUE,\n  relative = FALSE,\n  achromatic = \"none\"\n)\nciexyz.flowers <- colspace(vis.flowers, space = \"ciexyz\")\nhead(ciexyz.flowers)#>                               X         Y          Z         x\n#> Goodenia_heterophylla 0.2095846 0.2074402 0.30060475 0.2920513\n#> Goodenia_geniculata   0.6415362 0.6751982 0.42423209 0.3684943\n#> Goodenia_gracilis     0.5027874 0.4538738 0.01742707 0.5161620\n#> Xyris_operculata      0.2847275 0.2325247 0.22131809 0.3855117\n#> Eucalyptus_sp         0.4421178 0.4469747 0.40173521 0.3425072\n#> Faradaya_splendida    0.6545883 0.6532237 0.28855528 0.4100487\n#>                               y          z\n#> Goodenia_heterophylla 0.2890630 0.41888569\n#> Goodenia_geniculata   0.3878295 0.24367620\n#> Goodenia_gracilis     0.4659473 0.01789065\n#> Xyris_operculata      0.3148309 0.29965743\n#> Eucalyptus_sp         0.3462699 0.31122295\n#> Faradaya_splendida    0.4091939 0.18075745\nplot(ciexyz.flowers, pch = 21, bg = spec2rgb(flowers))\ncielab.flowers <- colspace(vis.flowers, space = \"cielab\")\nhead(cielab.flowers)#>                               X         Y          Z        L\n#> Goodenia_heterophylla 0.2095846 0.2074402 0.30060475 16.75107\n#> Goodenia_geniculata   0.6415362 0.6751982 0.42423209 54.52316\n#> Goodenia_gracilis     0.5027874 0.4538738 0.01742707 36.65092\n#> Xyris_operculata      0.2847275 0.2325247 0.22131809 18.77668\n#> Eucalyptus_sp         0.4421178 0.4469747 0.40173521 36.09381\n#> Faradaya_splendida    0.6545883 0.6532237 0.28855528 52.74869\n#>                               a          b\n#> Goodenia_heterophylla  3.110872 -18.616834\n#> Goodenia_geniculata   -4.478971  26.973109\n#> Goodenia_gracilis     22.697331  60.437370\n#> Xyris_operculata      21.382120  -2.596506\n#> Eucalyptus_sp          3.297259  -1.246816\n#> Faradaya_splendida     7.859790  45.351679\nplot(cielab.flowers, pch = 21, bg = spec2rgb(flowers))"},{"path":"analysing-data.html","id":"categorical-fly-colourspace","chapter":"3 Analysing Data","heading":"3.1.4.6.5 Categorical Fly Colourspace","text":"categorical colour vision model Troje (1993) model dipteran vision, based behavioural data blowfly Lucilia sp. assumes involvement four dipteran photoreceptor classes (R7 & R8 ‘pale’ ‘yellow’ subtypes), posits colour vision based two specific opponent mechanisms (R7p - R8p, R7y - R8y). model assumes colours perceptually grouped one four colour categories, flies unable distinguish colours fall within category.’ll use visual systems muscoid fly Musca domestica, begin estimating linear (.e. untransformed) quantum catches four photoreceptors.call colspace() simply estimate location stimuli categorical space difference relative stimulation ‘pale’ (R7p - R8p) ‘yellow’ (R7y - R8y) photoreceptor pairs:\\[\n\\begin{split}\nx &= R7_p - R8_p\\\\\ny &= R7_y - R8_y\n\\end{split}\n\\]simply signs differences define four possible fly-colour categories (p+y+, p-y+, p+y-, p-y-), can see associated plot.\nFigure 3.16: Flowers categorical colourspace Troje (1993).\n","code":"\nvis.flowers <- vismodel(flowers,\n  qcatch = \"Qi\",\n  visual = \"musca\",\n  achromatic = \"none\",\n  relative = TRUE\n)\ncat.flowers <- colspace(vis.flowers, space = \"categorical\")\n\nhead(cat.flowers)#>                              R7p        R7y       R8p       R8y\n#> Goodenia_heterophylla 0.05387616 0.18710662 0.4335986 0.3254187\n#> Goodenia_geniculata   0.02080098 0.08276030 0.3737592 0.5226795\n#> Goodenia_gracilis     0.01153130 0.02501417 0.1420049 0.8214496\n#> Xyris_operculata      0.01270353 0.12523419 0.4488377 0.4132246\n#> Eucalyptus_sp         0.03461949 0.14207848 0.3977208 0.4255812\n#> Faradaya_splendida    0.03599953 0.09188560 0.3129195 0.5591953\n#>                                x          y category     r.vec\n#> Goodenia_heterophylla -0.3797224 -0.1383120     p-y- 0.4041279\n#> Goodenia_geniculata   -0.3529583 -0.4399192     p-y- 0.5640110\n#> Goodenia_gracilis     -0.1304736 -0.7964355     p-y- 0.8070519\n#> Xyris_operculata      -0.4361342 -0.2879904     p-y- 0.5226390\n#> Eucalyptus_sp         -0.3631013 -0.2835027     p-y- 0.4606695\n#> Faradaya_splendida    -0.2769200 -0.4673097     p-y- 0.5431971\n#>                         h.theta lum\n#> Goodenia_heterophylla -2.792284  NA\n#> Goodenia_geniculata   -2.246954  NA\n#> Goodenia_gracilis     -1.733176  NA\n#> Xyris_operculata      -2.557993  NA\n#> Eucalyptus_sp         -2.478681  NA\n#> Faradaya_splendida    -2.105745  NA\nplot(cat.flowers, pch = 21, bg = spec2rgb(flowers))"},{"path":"analysing-data.html","id":"segment-classification","chapter":"3 Analysing Data","heading":"3.1.4.6.6 Segment Classification","text":"segment classification analysis (Endler 1990) assume particular visual system, instead tries classify colours manner captures common properties many vertebrate (invertebrate) visual systems. essence, breaks reflectance spectrum region interest four equally-spaced regions, measuring relative signal along regions. approximates tetrachromatic system ultraviolet, short, medium, long-wavelength sensitive photoreceptors.Though somewhat simplistic, model captures many properties , complex visual models, without many additional assumptions make. also provides results fairly intuitive colour space, angle corresponds hue distance centre corresponds chroma (Figure ; fact, variables S5 H4 summary.rspec() calculated relative segments).\nNote , segment analysis ranging 300 400 nm 700 nm corresponds quite closely human visual system colour wheel, wavelength range can analysed way, returning 360° hue space delimited range used.segment differences “opponents” calculated :\\[\n\\begin{split}\nLM &= \\frac{ R_\\lambda \\sum_{\\lambda={Q4}} R_\\lambda - \\sum_{\\lambda={Q2}} R_\\lambda }{\\sum_{\\lambda={min}}^{max}R_\\lambda}\\\\\nMS &= \\frac{ R_\\lambda \\sum_{\\lambda={Q3}} R_\\lambda - \\sum_{\\lambda={Q1}} R_\\lambda }{\\sum_{\\lambda={min}}^{max}R_\\lambda}\n\\end{split}\n\\]\\(Qi\\) represent interquantile distances (e.g. \\(Q1=ultraviolet\\), \\(Q2=blue\\), \\(Q3=green\\) \\(Q4=red\\))segment classification model obtained colspace() argument space = 'segment', following initial modelling vismodel(). example uses idealized reflectance spectra illustrate avian colour space defined segment classification maps human colour wheel:\nFigure 3.17: Idealized reflectance spectra projection axes segment classification\n","code":"\nfakedata1 <- vapply(\n  seq(100, 500, by = 20),\n  function(x) {\n    rowSums(cbind(\n      dnorm(300:700, x, 30),\n      dnorm(300:700, x + 400, 30)\n    ))\n  }, numeric(401)\n)\n\n# creating idealized specs with varying saturation\nfakedata2 <- vapply(\n  c(500, 300, 150, 105, 75, 55, 40, 30),\n  function(x) dnorm(300:700, 550, x),\n  numeric(401)\n)\n\nfakedata1 <- as.rspec(data.frame(wl = 300:700, fakedata1))#> wavelengths found in column 1\nfakedata1 <- procspec(fakedata1, \"max\")#> processing options applied:\n#> Scaling spectra to a maximum value of 1\nfakedata2 <- as.rspec(data.frame(wl = 300:700, fakedata2))#> wavelengths found in column 1\nfakedata2 <- procspec(fakedata2, \"sum\")#> processing options applied:\n#> Scaling spectra to a total area of 1\nfakedata2 <- procspec(fakedata2, \"min\")#> processing options applied:\n#> Scaling spectra to a minimum value of zero\n# converting reflectance to percentage\nfakedata1[, -1] <- fakedata1[, -1] * 100\nfakedata2[, -1] <- fakedata2[, -1] / max(fakedata2[, -1]) * 100\n\n# combining and converting to rspec\nfakedata.c <- data.frame(\n  wl = 300:700,\n  fakedata1[, -1],\n  fakedata2[, -1]\n)\nfakedata.c <- as.rspec(fakedata.c)#> wavelengths found in column 1\n# segment classification analysis\nseg.vis <- vismodel(fakedata.c,\n  visual = \"segment\",\n  achromatic = \"all\"\n)\nseg.fdc <- colspace(seg.vis, space = \"segment\")\n\n# plot results\nplot(seg.fdc, col = spec2rgb(fakedata.c))"},{"path":"analysing-data.html","id":"colourspace-distances-with-coldist","chapter":"3 Analysing Data","heading":"3.1.4.6.7 Colourspace Distances with coldist","text":"colourspace framework, colour distances can calculated simply Euclidean distances relative cone stimulation data, either log-transformed , depending defined. Euclidean distances can computed R using coldist() function colspace() output:Specialised colourspace models colour-hexagon, coc space, CIELab CIELCh models distance measures, returned default run coldist(). sure read ?coldist documentation, original publications, understand returned. example, run results colour-hexagon modelling coldist():chromatic contrasts dS achromatic contrasts dL expressed Euclidean distances hexagon, known ‘hexagon units’ (Chittka 1992). instead used colour-opponent coding space units city-bloc distances, CIELab model distances derived CIE colour-distance formula (2000).","code":"\nhead(coldist(tetra.flowers))#> Quantum catch are relative, distances may not be meaningful#> Calculating unweighted Euclidean distances#>                  patch1              patch2         dS dL\n#> 1 Goodenia_heterophylla Goodenia_geniculata 0.06695922 NA\n#> 2 Goodenia_heterophylla   Goodenia_gracilis 0.20467411 NA\n#> 3 Goodenia_heterophylla    Xyris_operculata 0.05407934 NA\n#> 4 Goodenia_heterophylla       Eucalyptus_sp 0.01901724 NA\n#> 5 Goodenia_heterophylla  Faradaya_splendida 0.05027645 NA\n#> 6 Goodenia_heterophylla  Gaultheria_hispida 0.03897671 NA\n# Model flower colours according to a honeybee\nvis.flowers <- vismodel(flowers,\n  visual = \"apis\",\n  qcatch = \"Ei\",\n  relative = FALSE,\n  vonkries = TRUE,\n  achromatic = \"l\",\n  bkg = \"green\"\n)\nhex.flowers <- colspace(vis.flowers, space = \"hexagon\")\n\n# Estimate colour distances. No need to specify\n# relative receptor densities, noise etc., which\n# only apply in the case of receptor-noise modelling\ndist.flowers <- coldist(hex.flowers)#> Calculating unweighted Euclidean distances\nhead(dist.flowers)#>                  patch1              patch2        dS dL\n#> 1 Goodenia_heterophylla Goodenia_geniculata 0.3207265 NA\n#> 2 Goodenia_heterophylla   Goodenia_gracilis 0.6870945 NA\n#> 3 Goodenia_heterophylla    Xyris_operculata 0.3025298 NA\n#> 4 Goodenia_heterophylla       Eucalyptus_sp 0.1111375 NA\n#> 5 Goodenia_heterophylla  Faradaya_splendida 0.2324927 NA\n#> 6 Goodenia_heterophylla  Gaultheria_hispida 0.2280836 NA"},{"path":"analysing-data.html","id":"distances-in-n-dimensions","chapter":"3 Analysing Data","heading":"3.1.4.6.8 Distances in N-Dimensions","text":"coldist() function longer limited di-, tri- tetrachromatic visual systems. function generalised, can now calculate colour distances n-dimensional visual phenotypes. means limit dimensionality visual systems may input, may prove useful modelling nature’s extremes (e.g. butterflies, mantis shrimp) simulation-based work. Naturally, since calculations aren’t largely implemented elsewhere, recommend caution validation results prior publication.\nFigure 3.18: Visual system pretend mantis shrimp 10 cones\n","code":"\n# Create an arbitrary visual phenotype with 10 photoreceptors\nfakemantisshrimp <- sensmodel(\n  c(\n    325, 350, 400,\n    425, 450, 500,\n    550, 600, 650,\n    700\n  ),\n  beta = FALSE, integrate = FALSE\n)\n\n# Convert to percentages, just to colour the plot\nfakemantisshrimp.colours <- fakemantisshrimp * 100\nfakemantisshrimp.colours[, \"wl\"] <- fakemantisshrimp[, \"wl\"]\n\nplot(fakemantisshrimp,\n  col = spec2rgb(fakemantisshrimp.colours), lwd = 2,\n  ylab = \"Absorbance\"\n)\n# Run visual model and calculate colour distances\nvm.fms <- vismodel(flowers,\n  visual = fakemantisshrimp,\n  relative = FALSE, achromatic = FALSE\n)\n\nJND.fms <- coldist(vm.fms, n = c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5))#> Calculating noise-weighted Euclidean distances\nhead(JND.fms)#>                  patch1              patch2        dS dL\n#> 1 Goodenia_heterophylla Goodenia_geniculata 16.297557 NA\n#> 2 Goodenia_heterophylla   Goodenia_gracilis 48.390309 NA\n#> 3 Goodenia_heterophylla    Xyris_operculata 30.760482 NA\n#> 4 Goodenia_heterophylla       Eucalyptus_sp  6.044184 NA\n#> 5 Goodenia_heterophylla  Faradaya_splendida 15.901435 NA\n#> 6 Goodenia_heterophylla  Gaultheria_hispida 11.188246 NA"},{"path":"analysing-data.html","id":"analysing-spatial-data","chapter":"3 Analysing Data","heading":"3.2 Analysing Spatial Data","text":"pavo now allows combined analysis spectral data spatial data. Note ‘spatial’ data course include images, may also draw spatially-sampled spectra, explored . Thus much deals image-based processing analysis, images necessary many spatial analyses indeed may perform worse spectrally-based analyses cases. , image data seldom used without input spectral measurements. Even simple butterfly example , users first validate presence number discrete colours patch via spectral measurement visual modelling (.e. ‘spectral’ information), augmented image-based clustering priori identified patches extract ‘spatial’ information. Using uncalibrated images alone inferences colour pattern perception may well yield unreliable results, given radical differences human (camera) non-human animal perception.","code":""},{"path":"analysing-data.html","id":"image-based-colour-classification","chapter":"3 Analysing Data","heading":"3.2.1 Image-based colour classification","text":"first import images getimg(), functions similar manner getspec(). Since importing one image, can simply point function folder containing images, use parallel processing (possible) import jpg, bmp, png images folder. raw spectra, images also available package repository [][data-location], included package installation convenience.segmentation RGB images discrete colour-classes useful step road several analyses, carried pavo via classify(). function currently implements k-means clustering , offers flexibility way carried . simplest case, can specify image image(s) well number discrete colours , allow k-means clustering algorithm work. Note specification k, number discrete colours image, crucial step estimated priori beforehand, typically use visual modelling estimate number discriminable colours ‘objective’ manner. suite possible ways may achieved, though, one detailed part example 2.Since two images, (arguably) four three colours , including white background, can specify information using kcols, visualising results summary. summary function, plot = TRUE, also particularly useful understanding colour-class labels, ID’s, assigned colour, well visualising accuracy classification process, may enhanced specifying strongly-contrasting ‘false’ colours plotting col argument.\nFigure 3.19: k-means classified images butterflies, along identified colour palettes\noptions available, may particular use classification process producing results might expected. analysing similar images homologous colour patterns (e.g. individuals within species), specify single ‘reference’ image list initially classified, using refID, RGB centres identified reference image used pre-specified cluster centres subsequent images. helps ensure homologous pattern elements reliably identified classified images. classify() function also offers interactive option, via interactive = TRUE, wherein can interactively click representative colours within image (images individually), RGB values used cluster centres. particularly useful images erroneously classified, since standard k-means process randomly selects initial centres may (chance) miss smaller patches, confuse similar colours. specifying initial RGB centres interactively, can easier process distinguish ‘pull apart’ colours circumstances. Ultimately, several combinations options available classification, also documented help file. butterflies, example, use following (though ill-advised):","code":"\nbutterflies <- getimg(system.file(\"testdata/images/butterflies\", package = \"pavo\"))#> 2 files found; importing images.\nbutterflies_class <- classify(butterflies, kcols = c(4, 3))#> Image classification in progress...\n# Note that we could simply feed the list of\n# images to summary, rather than specifying\n# individual images, and they would progress\n# automatically with user input.\nsummary(butterflies_class[[2]], plot = TRUE)\n# Automatic classification.\nbutterflies_class <- classify(butterflies, kcols = c(4, 3))#> Image classification in progress...\n# Automatic classification using a reference image,\n# identified by name.\nbutterflies_class <- classify(butterflies,\n  refID = \"h_melpomene\",\n  kcols = 3\n)#> Image classification in progress...\n# Classification using interactively-specified centres for each image, with no\n# need to specify kcols (since it will be inferred from the numbers of colours selected)\nbutterflies_class <- classify(butterflies, interactive = TRUE)\n\n# Classification using interactively-specified centres\n# for the single reference image (here, the first in\n# the list). We could also specify reference image\n# using it's name, as above.\nbutterflies_class <- classify(butterflies,\n  refID = 1,\n  interactive = TRUE\n)"},{"path":"analysing-data.html","id":"adjacency-and-boundary-strength-analyses-and-overall-pattern-contrasts","chapter":"3 Analysing Data","heading":"3.2.2 Adjacency and Boundary Strength Analyses, and Overall Pattern Contrasts","text":"adjacency (Endler 2012) boundary strength (Endler, Cole, Kranz 2018) analyses offer powerful method quantifying various features colour pattern geometry. Briefly, process entails classifying grid-sampled locations within visual scene number discrete colour classes. may achieved using classify() described sampling now-classified image, /taking grid-sampled reflectance spectra across visual scene, visually modelling clustering results (per ‘method 1’ Endler 2012, example ). column-wise row-wise colour-class transitions adjacent points within grid tallied, suite summary statistics pattern structure — simple colour proportions, colour diversity pattern complexity — estimated. colour ‘distance’ adjacent colour classes known, might estimated using spectral data receptor-noise modelling via vismodel() coldist(), can also incorporated derive several measures salience patch boundaries (Endler, Cole, Kranz 2018). Finally, estimates hue, saturation, /brightness known discrete colour pattern, can included hsl argument general, area-weighted measures overall pattern contrast (Endler Mielke 2005). pavo, carried adjacent() function, takes several arguments well understood.","code":""},{"path":"analysing-data.html","id":"example-1-simple-mounted-butterflies","chapter":"3 Analysing Data","heading":"3.2.2.1 Example 1 (simple): mounted butterflies","text":"’ll begin simple example using mounted butterflies, first loading classifying images manner outlined . adjacency analysis proper, ’ll specify full x-dimension scale 200 mm using xscale (ignored specify scales using procimg()), sampling density 200, 200 x 200 grid. Since white background images fake interest, also exclude specifying colour-class ID corresponds (complex backgrounds, instead use procimg(), , ignore argument).output suite statistics describing colour pattern structure geometry tidy data frame , since fed list images, contains one row samples. always, function’s help file (?adjacent) summarises meaning output variable, original references listed therein contain full discussion. Note output NA, might occur focal statistic simply makes sense image question (transition frequency colour categories 3 4, image contains 3 colour categories). Others may result give adjacent() enough information, colour-distances required calculate boundary-strength statistics, colourmetrics required overall pattern contrast. give function information, can see final variables now contain sensible output.","code":"\n# Load up our images\nbutterflies <- getimg(system.file(\"testdata/images/butterflies\", package = \"pavo\"))#> 2 files found; importing images.\n# Automatically classify discrete colour patches (as confirmed\n# by spectral modelling) using k-means clustering, with values\n# of 'k' that have been validated a priori.\nbutterflies_class <- classify(butterflies, kcols = c(4, 3))#> Image classification in progress...\n# Run the adjacency analysis, subsampling the image in a\n# 200x200 grid, and excluding the white background.\nbutterflies_adj <- adjacent(butterflies_class,\n  xscale = 200,\n  xpts = 200,\n  bkgID = 1\n)\n\n# Take a look\nhead(butterflies_adj)#>             k     N n_off        p_1       p_2       p_3      p_4\n#> h_melpomene 4 54064  5111 0.03511029 0.5833824 0.3408824 0.040625\n#> papilio     3 63241  3883 0.16220126 0.6441824 0.1936164       NA\n#>                   q_1_1      q_1_2     q_2_2      q_1_3      q_2_3\n#> h_melpomene 0.006510802 0.01294762 0.5649970 0.03486608 0.01864457\n#> papilio     0.138059170 0.00713145 0.6329596 0.04299426 0.01127433\n#>                 q_3_3       q_1_4      q_3_4      q_4_4     t_1_2\n#> h_melpomene 0.3071175 0.009821693 0.01825614 0.02683856 0.1369595\n#> papilio     0.1675812          NA         NA         NA 0.1161473\n#>                 t_1_3     t_2_3     t_1_4     t_3_4          m\n#> h_melpomene 0.3688124 0.1972217 0.1038936 0.1931129 0.09395221\n#> papilio     0.7002318 0.1836209        NA        NA 0.06102033\n#>                    m_r       m_c         A       Sc       St\n#> h_melpomene 0.08779412 0.1001103 0.8769739 2.176663 4.136277\n#> papilio     0.06937107 0.0526696 1.3170989 2.088697 1.860357\n#>                    Jc        Jt         B        Rt Rab m_dS s_dS\n#> h_melpomene 0.5441657 0.6893795 0.4558795 0.4803734   1   NA   NA\n#> papilio     0.6962322 0.6201188 0.2191604 0.5375314   1   NA   NA\n#>             cv_dS m_dL s_dL cv_dL m_hue s_hue var_hue m_sat s_sat\n#> h_melpomene    NA   NA   NA    NA    NA    NA      NA    NA    NA\n#> papilio        NA   NA   NA    NA    NA    NA      NA    NA    NA\n#>             cv_sat m_lum s_lum cv_lum\n#> h_melpomene     NA    NA    NA     NA\n#> papilio         NA    NA    NA     NA\n# Create a fake matrix of pairwise colour- and luminance\n# distances between all colour patten elements, as might\n# be attained through visual modelling of spectral data.\ndistances <- data.frame(\n  c1 = c(1, 1, 2),\n  c2 = c(2, 3, 3),\n  dS = c(10.6, 5.1, 4.4),\n  dL = c(1.1, 2.5, 3.2)\n)\n\n# Take a look\ndistances#>   c1 c2   dS  dL\n#> 1  1  2 10.6 1.1\n#> 2  1  3  5.1 2.5\n#> 3  2  3  4.4 3.2\n# And our fake hue angles (in radians), saturation,\n# and luminance values, for each colour pattern element\nhsl_vals <- data.frame(\n  patch = 1:3,\n  hue = c(1.2, 2.2, 1.6),\n  lum = c(10, 5, 7),\n  sat = c(3.5, 1.1, 6.3)\n)\n\n# Take a look\nhsl_vals#>   patch hue lum sat\n#> 1     1 1.2  10 3.5\n#> 2     2 2.2   5 1.1\n#> 3     3 1.6   7 6.3\n# Now feed this information into the adjacency analysis\n# using the 'less-colourful' of our two images, for convenience\n# (though this could be readily extended to include a list\n# of images along with a list of distances and hsl values)\nadjacent(butterflies_class[[2]],\n  xscale = 200, xpts = 200,\n  bkgID = 1, coldists = distances, hsl = hsl_vals\n)#>         k     N n_off       p_1       p_2       p_3     q_1_1\n#> papilio 3 63241  3883 0.1622013 0.6441824 0.1936164 0.1380592\n#>              q_1_2     q_2_2      q_1_3      q_2_3     q_3_3\n#> papilio 0.00713145 0.6329596 0.04299426 0.01127433 0.1675812\n#>             t_1_2     t_1_3     t_2_3          m        m_r\n#> papilio 0.1161473 0.7002318 0.1836209 0.06102033 0.06937107\n#>               m_c        A       Sc       St        Jc        Jt\n#> papilio 0.0526696 1.317099 2.088697 1.860357 0.6962322 0.6201188\n#>                 B        Rt Rab     m_dS     s_dS     cv_dS\n#> papilio 0.2191604 0.5375314   1 5.610276 2.688625 0.4792323\n#>             m_dL      s_dL     cv_dL    m_hue     s_hue   var_hue\n#> papilio 2.465928 0.8272175 0.3354589 1.663715 0.4154308 0.0826731\n#>            m_sat    s_sat   cv_sat    m_lum    s_lum    cv_lum\n#> papilio 2.496088 2.845585 1.140018 6.198239 2.551657 0.4116745"},{"path":"analysing-data.html","id":"example-2-complex-whole-visual-environments","chapter":"3 Analysing Data","heading":"3.2.2.2 Example 2 (complex): whole visual environments","text":"course colour patterns always simple, may want analyse spatial geometry complex subtle scenes. cases, may preferable largely forego image-based clustering classification altogether instead use spectral data directly adjacency-style analysis (per ‘method 1’ Endler 2012). One approach us take spectral measurements across patch evenly-spaced grid\nFigure 3.20: cryptic lizard, along possible sampling grid spectral measurement.\nsake example ’ll simulate 100 reflectance spectra, though collected following grid. ’ll creating four similar groups 25 spectra, also allow us get sense clustering methods perform. course real spectra variable, principles apply.Now instead calling cluster() image arbitrarily selecting kcols (likely quite inaccurate due complexity scene), can visually model spectra, calculate colour-distances , cluster results data-image can fed directly adjacent(). ’ll use centroid-based ‘hartigan’ clustering method via package NbClust, numerous possible approaches might used, closely considered reference original methods’ publications.approach identified four distinct colour patches, simulated. able feed information directly adjacent() need arrange now-classified spectral data xyz data-image matrix, x y coordinates specify location sample scene, z values location specify colour-class, group, sample classified (integer). Many clustering packages offers data’s classification output form, can simply rearrange original 10 x 10 sampling matrix passing adjacent().output reflects several aspects simulated dataset, reassuring. four colour classes (k= 4) equal proportion (p_x), 180 transitions total (N, 9 transitions per row/column x 10 rows/columns), colour diversity (Sc) equals k, relative colour diversity (Jc) equals 1, since colours occur equal proportions.","code":"\n# Load up our image of a camouflaged lizard\nlizard <- getimg(system.file(\"testdata/images/vig/\", package = \"pavo\"))#> 1 files found; importing images.\n# Take a look at it\nplot(lizard)\n\n# And overlay a simple 'sampling grid' that might\n# guide us as to where we should collect our reflectance\n# measurements. Note that the grid here is likely too\n# coarse to capture the necessary detail, though the\n# sampling density is something to be closely considered on a case-by-case basis\nplot(lizard)\npoints(\n  expand.grid(\n    seq(0, dim(lizard)[1], 25),\n    seq(0, dim(lizard)[1], 25)\n  ),\n  pch = 16, col = \"red\"\n)\nset.seed(12352) # For reprodicubility\n\n# Generate some fake spectra that were grid-sampled across our scene\nfakescene <- cbind(\n  do.call(\n    cbind,\n    lapply(1:25, function(x) dnorm(300:700, runif(1, 320, 330), 20))\n  ),\n  do.call(\n    cbind,\n    lapply(1:25, function(x) dnorm(300:700, runif(1, 440, 450), 20))\n  ),\n  do.call(\n    cbind,\n    lapply(1:25, function(x) dnorm(300:700, runif(1, 550, 560), 20))\n  ),\n  do.call(\n    cbind,\n    lapply(1:25, function(x) dnorm(300:700, runif(1, 650, 660), 20))\n  )\n)\n\n# Convert them to rspce objects\nfakescene <- as.rspec(data.frame(wl = 300:700, fakescene))\n# Visually model our spectra in a tetrahedral model of the blue\n# tit, specifying relative = FALSE so that we can estimate\n# noise-calibrated distances.\nvis.fakescene <- vismodel(fakescene,\n  visual = \"bluetit\",\n  relative = FALSE,\n  scale = 10000\n)\n\n# Calculate noise-weighted distances, before converting\n# them to xyz coordinates in noise-corrected colourspace.\njnd.fakescene <- jnd2xyz(coldist(vis.fakescene))\n\n# Create a distance matrix, for clustering\njnd.mat <- dist(jnd.fakescene,\n  method = \"euclidean\",\n  diag = FALSE\n)\n\n# Zero all distance < 1 ('just noticeable distance',\n# in this model), which corresponds to a theoretical\n# threshold of discrimination in the receptor-noise limited\n# model.\njnd.mat[which(jnd.mat < 1)] <- 0\n\n# Load up a library and use k-means clustering to\n# estimate the number of discrete colours present in our sample.\nlibrary(NbClust)\nclust <- NbClust(jnd.fakescene,\n  diss = jnd.mat,\n  distance = NULL,\n  method = \"centroid\",\n  index = \"hartigan\"\n)\nclust$Best.nc#> Number_clusters     Value_Index \n#>           4.000        1639.353\n# Rearrange the data into a colour-classified\n# image matrix, and take a look at it. Note that\n# is the same structure as the output of 'classify()'.\nmat.fakescene <- matrix(as.numeric(unlist(clust$Best.partition)), 10, 10)\nhead(mat.fakescene)#>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#> [1,]    1    1    1    2    2    3    3    3    4     4\n#> [2,]    1    1    1    2    2    3    3    3    4     4\n#> [3,]    1    1    1    2    2    3    3    3    4     4\n#> [4,]    1    1    1    2    2    3    3    3    4     4\n#> [5,]    1    1    1    2    2    3    3    3    4     4\n#> [6,]    1    1    2    2    2    3    3    4    4     4\n# Run the adjacency analysis\nadjacent(mat.fakescene, xscale = 200)#>     k   N n_off  p_1  p_2  p_3  p_4     q_1_1      q_1_2     q_2_2\n#> img 4 180    32 0.25 0.25 0.25 0.25 0.2055556 0.06111111 0.2055556\n#>          q_2_3     q_3_3      q_3_4     q_4_4   t_1_2  t_2_3\n#> img 0.05555556 0.2055556 0.06111111 0.2055556 0.34375 0.3125\n#>       t_3_4     m   m_r   m_c  A Sc       St Jc        Jt  B Rt Rab\n#> img 0.34375 0.008 0.015 0.001 15  4 2.994152  1 0.4990253 NA NA  NA\n#>     m_dS s_dS cv_dS m_dL s_dL cv_dL m_hue s_hue var_hue m_sat s_sat\n#> img   NA   NA    NA   NA   NA    NA    NA    NA      NA    NA    NA\n#>     cv_sat m_lum s_lum cv_lum\n#> img     NA    NA    NA     NA"},{"path":"spectral-shape-descriptors.html","id":"spectral-shape-descriptors","chapter":"4 Spectral shape descriptors","heading":"4 Spectral shape descriptors","text":"table adapted Montgomerie (2006) lists spectral descriptors\ncomputed summary function pavo.\\(R_i\\): percentage (proportional) reflectance \\(\\)th wavelength\\(\\lambda_{max}\\), \\(\\lambda_{min}\\): upper lower (respectively) limits \nwavelengths\\(n_w\\): number wavelength intervals used calculate \\(B_T\\)\\(R_{max}\\), \\(R_{min}\\): maximum minimum percent reflectances, respectively\\(\\lambda_{R_{max}}\\): wavelength maximum reflectance\\(b\\text{max}_{neg}\\), \\(b\\text{max}_{pos}\\): maximum negative positive slopes\nreflectance curve region interest\\(B_r\\), \\(B_y\\), \\(B_g\\), \\(B_b\\): total brightness red (\\(r=625-700\\,nm\\)), yellow\n(\\(y=550-625\\,nm\\)), green (\\(g=475-550\\,nm\\)) blue (\\(b=400-475\\,nm\\)) segments\nspectrum\\(\\lambda_{R_{mid}}\\): wavelength reflectance midpoint \\(R_{max}\\)\n\\(R_{min}\\) (.e., \\(\\frac{R_{max}+R_{min}}{2}\\))","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
